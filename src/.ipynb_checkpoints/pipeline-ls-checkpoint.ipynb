{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['images', 'test.csv', 'sample_submission.csv', 'train.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import isfile\n",
    "import torch.nn.init as init\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from PIL import Image, ImageFilter\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, LabelEncoder, OneHotEncoder\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from torch.optim import Adam, SGD, RMSprop\n",
    "import time\n",
    "import math\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.autograd import Variable\n",
    "import torch.functional as F\n",
    "from tqdm import tqdm\n",
    "from sklearn import metrics\n",
    "import urllib\n",
    "import pickle\n",
    "import cv2\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "import seaborn as sns\n",
    "import random\n",
    "import sys\n",
    "import shutil\n",
    "import albumentations\n",
    "from albumentations import pytorch as AT\n",
    "\n",
    "from apex import amp\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "\n",
    "from torchcontrib.optim import SWA\n",
    "\n",
    "# torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.special\n",
    "\n",
    "SEED = 42\n",
    "base_dir = '../input'\n",
    "def seed_everything(seed=SEED):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYHTONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_everything(SEED)\n",
    "\n",
    "def l2_norm(input,axis=1):\n",
    "    norm = torch.norm(input,2,axis,True)\n",
    "    output = torch.div(input, norm)\n",
    "    return output\n",
    "\n",
    "sigmoid = lambda x: scipy.special.expit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize tools\n",
    "def visualize(**images):\n",
    "    \"\"\"PLot images in one row.\"\"\"\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(16, 5))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image)\n",
    "    plt.show()\n",
    "    \n",
    "def test_transform(img_path, transform):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = transform(image = img)['image']\n",
    "    visualize(image = img)\n",
    "    \n",
    "def write_aug(img_path, transform, num=30):\n",
    "    img = cv2.imread(img_path)\n",
    "    for i in range(num):\n",
    "        t = transform(image = img)['image']\n",
    "        cv2.imwrite('./aug/'+str(i)+'.jpg',t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD = 5\n",
    "BATCH_SIZE = 32  ## batch size * accumulate ~= 64 (64x1, 32x2, 24x3, 16*4)\n",
    "ACCUMULATE = 2\n",
    "LR = 1e-3\n",
    "EPOCH = 20\n",
    "IMG_SIZE = 384  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP = 1\n",
    "while os.path.exists('./exp/exp%d'%EXP):\n",
    "    EXP+=1\n",
    "os.makedirs('./exp/exp%d'%EXP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv( base_dir + '/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>healthy</th>\n",
       "      <th>multiple_diseases</th>\n",
       "      <th>rust</th>\n",
       "      <th>scab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Train_1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Train_2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Train_3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Train_4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_id  healthy  multiple_diseases  rust  scab\n",
       "0  Train_0        0                  0     0     1\n",
       "1  Train_1        0                  1     0     0\n",
       "2  Train_2        1                  0     0     0\n",
       "3  Train_3        0                  0     1     0\n",
       "4  Train_4        1                  0     0     0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlantDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.df = dataframe\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        row = self.df.iloc[idx]\n",
    "        label = np.argmax([row.healthy, row.multiple_diseases, row.rust, row.scab])\n",
    "#         if label[1] == 1: # fix anno bug in label (should post process to recover raw label)\n",
    "#             label[2] = 1\n",
    "#             label[3] = 1\n",
    "#         label = np.array(label)\n",
    "\n",
    "        path = base_dir + '/images/' + row.image_id + '.jpg'\n",
    "        image = cv2.imread(path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image=image)\n",
    "            \n",
    "        image = image['image']\n",
    "            \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fangxi/miniconda3/lib/python3.7/site-packages/albumentations/augmentations/transforms.py:2908: UserWarning: Using lambda is incompatible with multiprocessing. Consider using regular functions or partial().\n",
      "  \"Using lambda is incompatible with multiprocessing. \"\n",
      "/home/fangxi/miniconda3/lib/python3.7/site-packages/albumentations/augmentations/transforms.py:2908: UserWarning: Using lambda is incompatible with multiprocessing. Consider using regular functions or partial().\n",
      "  \"Using lambda is incompatible with multiprocessing. \"\n"
     ]
    }
   ],
   "source": [
    "def pre_trans(x, cols, rows):\n",
    "    return (x * 2.0 - 1.0)\n",
    "\n",
    "train_transform_advprop = albumentations.Compose([\n",
    "    albumentations.Resize(IMG_SIZE, IMG_SIZE),\n",
    "    albumentations.RandomRotate90(p=0.5),\n",
    "    albumentations.Transpose(p=0.5),\n",
    "    albumentations.Flip(p=0.5),\n",
    "    albumentations.OneOf([\n",
    "        albumentations.RandomBrightness(0.15, p=1), \n",
    "        albumentations.RandomContrast(0.15, p=1),\n",
    "        albumentations.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=20, p=1),\n",
    "    ], p=0.5), \n",
    "    albumentations.OneOf([\n",
    "        albumentations.ISONoise(color_shift=(0.01, 0.03), intensity=(0.1, 0.3)),\n",
    "        albumentations.IAASharpen(alpha=(0.1, 0.3), lightness=(0.5, 1.0)),\n",
    "    ], p=0.5), \n",
    "    albumentations.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.2, rotate_limit=45, border_mode=1, p=0.5),\n",
    "    albumentations.Lambda(image = pre_trans),\n",
    "    AT.ToTensor(),\n",
    "    ])\n",
    "\n",
    "\n",
    "test_transform = albumentations.Compose([\n",
    "    albumentations.Resize(IMG_SIZE, IMG_SIZE),\n",
    "    albumentations.Lambda(image = pre_trans),\n",
    "    AT.ToTensor(),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1454 | test: 367\n",
      "Train: 1456 | test: 365\n",
      "Train: 1458 | test: 363\n",
      "Train: 1458 | test: 363\n",
      "Train: 1458 | test: 363\n"
     ]
    }
   ],
   "source": [
    "sfolder = StratifiedKFold(n_splits=FOLD,random_state=SEED,shuffle=True)\n",
    "\n",
    "tr_idx = []\n",
    "val_idx = []\n",
    "\n",
    "Y = np.array(train_df[['healthy','multiple_diseases','rust','scab']])\n",
    "Y = np.argmax(Y, axis=1)\n",
    "\n",
    "for train, val in sfolder.split(range(len(train_df)), Y):\n",
    "    tr_idx.append(train)\n",
    "    val_idx.append(val)\n",
    "    print('Train: %s | test: %s' % (len(train), len(val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.ranger import RangerVA \n",
    "from utils.lr_scheduler import CosineAnnealingWarmUpRestarts\n",
    "from utils.label_smooth import LSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class smooth_L1_ohem(nn.Module):\n",
    "    def __init__(self, top_k=0.5):\n",
    "        super(smooth_L1_ohem, self).__init__()\n",
    "        self.top_k = top_k\n",
    "        self.loss = nn.SmoothL1Loss(reduction='none')\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        loss = self.loss(input, target)\n",
    "        if self.top_k == 1:\n",
    "            return torch.mean(loss)\n",
    "        else:\n",
    "            valid_loss, idxs = torch.topk(loss, int(self.top_k * loss.size()[0]), dim=0)    \n",
    "            return torch.mean(valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaptiveConcatPool2d(nn.Module):\n",
    "    def __init__(self, sz=None):\n",
    "        super().__init__()\n",
    "        sz = sz or (1,1)\n",
    "        self.ap = nn.AdaptiveAvgPool2d(sz)\n",
    "        self.mp = nn.AdaptiveMaxPool2d(sz)\n",
    "    def forward(self, x):\n",
    "        return torch.cat([self.mp(x), self.ap(x)], 1)\n",
    "    \n",
    "def mish(input):\n",
    "    return input * torch.tanh(F.softplus(input))\n",
    "       \n",
    "class Mish(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, input):\n",
    "        return mish(input)\n",
    "\n",
    "def gem(x, p=3, eps=1e-6):\n",
    "    return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\n",
    "\n",
    "class GeM(nn.Module):\n",
    "    def __init__(self, p=3, eps=1e-6):\n",
    "        super(GeM,self).__init__()\n",
    "        self.p = Parameter(torch.ones(1)*p)\n",
    "        self.eps = eps\n",
    "    def forward(self, x):\n",
    "        return gem(x, p=self.p, eps=self.eps)       \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + ', ' + 'eps=' + str(self.eps) + ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epoch):\n",
    "    model_conv.train()         \n",
    "    avg_loss = 0.\n",
    "    optimizer.zero_grad()\n",
    "    for idx, (imgs, labels) in enumerate(train_loader):\n",
    "        imgs_train, labels_train = imgs.cuda(), labels.cuda()\n",
    "        output_train = model_conv(imgs_train)\n",
    "        loss = criterion(output_train,labels_train)\n",
    "        #loss.backward()\n",
    "        with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "            scaled_loss.backward()\n",
    "        if ((idx+1)%ACCUMULATE==0):\n",
    "            torch.nn.utils.clip_grad_norm_(model_conv.parameters(), max_norm=5.0, norm_type=2)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            scheduler.step()\n",
    "        avg_loss += loss.item() / len(train_loader)  \n",
    "    return avg_loss\n",
    "\n",
    "def test_model():    \n",
    "    avg_val_loss = 0.\n",
    "    model_conv.eval()\n",
    "    y_pred_val = np.zeros((len(valset), 4))\n",
    "    y_true_val = np.zeros((len(valset)))\n",
    "    with torch.no_grad():\n",
    "        for idx, (imgs, labels) in enumerate(val_loader):\n",
    "            imgs_vaild, labels_vaild = imgs.cuda(), labels.cuda()\n",
    "            output_test = model_conv(imgs_vaild)\n",
    "            avg_val_loss += (criterion_test(output_test, labels_vaild).item() / len(val_loader)) \n",
    "            a = labels_vaild.detach().cpu().numpy().astype(np.int) #.reshape(-1,4)\n",
    "            b = output_test.detach().cpu().numpy() #.reshape(-1,4)\n",
    "\n",
    "            y_pred_val[idx*BATCH_SIZE:idx*BATCH_SIZE+b.shape[0]] = b\n",
    "            y_true_val[idx*BATCH_SIZE:idx*BATCH_SIZE+b.shape[0]] = a\n",
    "            \n",
    "    acc = sum(np.argmax(y_pred_val, axis=1) == y_true_val) / len(y_pred_val)\n",
    "\n",
    "    return avg_val_loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(fold):\n",
    "    best_avg_loss = 100.0 \n",
    "    best_acc = 0.0\n",
    "\n",
    "    ### training\n",
    "    for epoch in range(EPOCH):   \n",
    "        print('lr:', scheduler.get_lr()[0]) \n",
    "        start_time        = time.time()\n",
    "        avg_loss          = train_model(epoch)\n",
    "        avg_val_loss, acc = test_model()\n",
    "        elapsed_time      = time.time() - start_time \n",
    "        print('Epoch {}/{} \\t loss={:.4f} \\t val_loss={:.4f} \\t val_acc={:.4f} \\t time={:.2f}s'.format(\n",
    "            epoch + 1, EPOCH, avg_loss, avg_val_loss, acc, elapsed_time))\n",
    "\n",
    "        if avg_val_loss < best_avg_loss:\n",
    "            best_avg_loss = avg_val_loss\n",
    "            \n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            torch.save(model_conv.state_dict(), './exp/exp' + str(EXP) + '/efficientnet-b5-best' + str(fold) + '.pth')\n",
    "            print('model saved!')\n",
    "\n",
    "        print('=================================')   \n",
    "\n",
    "    print('best loss:', best_avg_loss, 'best accuracy:', best_acc)\n",
    "    \n",
    "    return best_avg_loss, best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ********** Fold 0 **********\n",
      "\n",
      "Loaded pretrained weights for efficientnet-b5\n",
      "lr: 5e-05\n",
      "Epoch 1/30 \t loss=1.2454 \t val_loss=1.0951 \t val_acc=0.7139 \t time=62.47s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.001\n",
      "Epoch 2/30 \t loss=0.7223 \t val_loss=0.8585 \t val_acc=0.7520 \t time=62.71s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.0009713539948733066\n",
      "Epoch 3/30 \t loss=0.6536 \t val_loss=0.2752 \t val_acc=0.9210 \t time=62.98s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.0008888711104815146\n",
      "Epoch 4/30 \t loss=0.5591 \t val_loss=0.2791 \t val_acc=0.9292 \t time=63.56s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.0007625\n",
      "Epoch 5/30 \t loss=0.5167 \t val_loss=0.2183 \t val_acc=0.9264 \t time=63.52s\n",
      "=================================\n",
      "lr: 0.000607482884391792\n",
      "Epoch 6/30 \t loss=0.5097 \t val_loss=0.1898 \t val_acc=0.9591 \t time=62.98s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.00044251711560820814\n",
      "Epoch 7/30 \t loss=0.4713 \t val_loss=0.1639 \t val_acc=0.9537 \t time=63.26s\n",
      "=================================\n",
      "lr: 0.0002875000000000001\n",
      "Epoch 8/30 \t loss=0.4354 \t val_loss=0.1702 \t val_acc=0.9673 \t time=63.51s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.0001611288895184855\n",
      "Epoch 9/30 \t loss=0.4254 \t val_loss=0.1528 \t val_acc=0.9755 \t time=63.09s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 7.86460051266936e-05\n",
      "Epoch 10/30 \t loss=0.4237 \t val_loss=0.1553 \t val_acc=0.9700 \t time=63.93s\n",
      "=================================\n",
      "lr: 5e-05\n",
      "Epoch 11/30 \t loss=0.4136 \t val_loss=0.1573 \t val_acc=0.9728 \t time=65.30s\n",
      "=================================\n",
      "lr: 0.0002\n",
      "Epoch 12/30 \t loss=0.4096 \t val_loss=0.1631 \t val_acc=0.9646 \t time=63.90s\n",
      "=================================\n",
      "lr: 0.00019886058147591563\n",
      "Epoch 13/30 \t loss=0.4146 \t val_loss=0.1784 \t val_acc=0.9591 \t time=63.96s\n",
      "=================================\n",
      "lr: 0.00019547694655894313\n",
      "Epoch 14/30 \t loss=0.4038 \t val_loss=0.1516 \t val_acc=0.9700 \t time=64.30s\n",
      "=================================\n",
      "lr: 0.00018995190528383292\n",
      "Epoch 15/30 \t loss=0.3994 \t val_loss=0.1614 \t val_acc=0.9673 \t time=64.57s\n",
      "=================================\n",
      "lr: 0.00018245333323392338\n",
      "Epoch 16/30 \t loss=0.3836 \t val_loss=0.1314 \t val_acc=0.9782 \t time=64.62s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.00017320907072649046\n",
      "Epoch 17/30 \t loss=0.3949 \t val_loss=0.1529 \t val_acc=0.9700 \t time=63.51s\n",
      "=================================\n",
      "lr: 0.00016250000000000002\n",
      "Epoch 18/30 \t loss=0.3886 \t val_loss=0.1493 \t val_acc=0.9700 \t time=63.63s\n",
      "=================================\n",
      "lr: 0.00015065151074942517\n",
      "Epoch 19/30 \t loss=0.3891 \t val_loss=0.1551 \t val_acc=0.9673 \t time=64.42s\n",
      "=================================\n",
      "lr: 0.0001380236133250198\n",
      "Epoch 20/30 \t loss=0.3920 \t val_loss=0.1539 \t val_acc=0.9728 \t time=64.35s\n",
      "=================================\n",
      "lr: 0.000125\n",
      "Epoch 21/30 \t loss=0.3799 \t val_loss=0.1577 \t val_acc=0.9700 \t time=64.48s\n",
      "=================================\n",
      "lr: 0.00011197638667498024\n",
      "Epoch 22/30 \t loss=0.3795 \t val_loss=0.1583 \t val_acc=0.9646 \t time=64.15s\n",
      "=================================\n",
      "lr: 9.934848925057487e-05\n",
      "Epoch 23/30 \t loss=0.3793 \t val_loss=0.1524 \t val_acc=0.9728 \t time=63.89s\n",
      "=================================\n",
      "lr: 8.750000000000001e-05\n",
      "Epoch 24/30 \t loss=0.3791 \t val_loss=0.1405 \t val_acc=0.9700 \t time=64.01s\n",
      "=================================\n",
      "lr: 7.679092927350956e-05\n",
      "Epoch 25/30 \t loss=0.3771 \t val_loss=0.1488 \t val_acc=0.9728 \t time=64.55s\n",
      "=================================\n",
      "lr: 6.754666676607666e-05\n",
      "Epoch 26/30 \t loss=0.3762 \t val_loss=0.1472 \t val_acc=0.9728 \t time=64.86s\n",
      "=================================\n",
      "lr: 6.004809471616712e-05\n",
      "Epoch 27/30 \t loss=0.3742 \t val_loss=0.1468 \t val_acc=0.9728 \t time=63.46s\n",
      "=================================\n",
      "lr: 5.4523053441056884e-05\n",
      "Epoch 28/30 \t loss=0.3715 \t val_loss=0.1415 \t val_acc=0.9755 \t time=64.14s\n",
      "=================================\n",
      "lr: 5.11394185240844e-05\n",
      "Epoch 29/30 \t loss=0.3724 \t val_loss=0.1494 \t val_acc=0.9728 \t time=63.69s\n",
      "=================================\n",
      "lr: 5e-05\n",
      "Epoch 30/30 \t loss=0.3739 \t val_loss=0.1412 \t val_acc=0.9755 \t time=63.68s\n",
      "=================================\n",
      "best loss: 0.13139178506706073 best accuracy: 0.9782016348773842\n",
      "\n",
      " ********** Fold 1 **********\n",
      "\n",
      "Loaded pretrained weights for efficientnet-b5\n",
      "lr: 5e-05\n",
      "Epoch 1/30 \t loss=1.2526 \t val_loss=1.3127 \t val_acc=0.7699 \t time=65.66s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.001\n",
      "Epoch 2/30 \t loss=0.6820 \t val_loss=0.2787 \t val_acc=0.9123 \t time=64.08s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.0009713539948733066\n",
      "Epoch 3/30 \t loss=0.5826 \t val_loss=0.3410 \t val_acc=0.9370 \t time=64.04s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.0008888711104815146\n",
      "Epoch 4/30 \t loss=0.5374 \t val_loss=0.3187 \t val_acc=0.9178 \t time=64.78s\n",
      "=================================\n",
      "lr: 0.0007625\n",
      "Epoch 5/30 \t loss=0.5566 \t val_loss=0.2132 \t val_acc=0.9562 \t time=65.33s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.000607482884391792\n",
      "Epoch 6/30 \t loss=0.5134 \t val_loss=0.1691 \t val_acc=0.9644 \t time=65.27s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.00044251711560820814\n",
      "Epoch 7/30 \t loss=0.4648 \t val_loss=0.1751 \t val_acc=0.9644 \t time=64.77s\n",
      "=================================\n",
      "lr: 0.0002875000000000001\n",
      "Epoch 8/30 \t loss=0.4536 \t val_loss=0.1464 \t val_acc=0.9671 \t time=64.10s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.0001611288895184855\n",
      "Epoch 9/30 \t loss=0.4293 \t val_loss=0.1795 \t val_acc=0.9534 \t time=64.56s\n",
      "=================================\n",
      "lr: 7.86460051266936e-05\n",
      "Epoch 10/30 \t loss=0.4175 \t val_loss=0.1601 \t val_acc=0.9671 \t time=65.01s\n",
      "=================================\n",
      "lr: 5e-05\n",
      "Epoch 11/30 \t loss=0.4058 \t val_loss=0.1595 \t val_acc=0.9699 \t time=64.02s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.0002\n",
      "Epoch 12/30 \t loss=0.4123 \t val_loss=0.1548 \t val_acc=0.9726 \t time=63.99s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.00019886058147591563\n",
      "Epoch 13/30 \t loss=0.4179 \t val_loss=0.1812 \t val_acc=0.9671 \t time=63.63s\n",
      "=================================\n",
      "lr: 0.00019547694655894313\n",
      "Epoch 14/30 \t loss=0.4065 \t val_loss=0.1680 \t val_acc=0.9616 \t time=63.96s\n",
      "=================================\n",
      "lr: 0.00018995190528383292\n",
      "Epoch 15/30 \t loss=0.4068 \t val_loss=0.1543 \t val_acc=0.9671 \t time=65.31s\n",
      "=================================\n",
      "lr: 0.00018245333323392338\n",
      "Epoch 16/30 \t loss=0.4065 \t val_loss=0.1748 \t val_acc=0.9589 \t time=64.28s\n",
      "=================================\n",
      "lr: 0.00017320907072649046\n",
      "Epoch 17/30 \t loss=0.3931 \t val_loss=0.1692 \t val_acc=0.9644 \t time=64.56s\n",
      "=================================\n",
      "lr: 0.00016250000000000002\n",
      "Epoch 18/30 \t loss=0.3914 \t val_loss=0.1577 \t val_acc=0.9699 \t time=63.95s\n",
      "=================================\n",
      "lr: 0.00015065151074942517\n",
      "Epoch 19/30 \t loss=0.3860 \t val_loss=0.1645 \t val_acc=0.9699 \t time=64.68s\n",
      "=================================\n",
      "lr: 0.0001380236133250198\n",
      "Epoch 20/30 \t loss=0.3875 \t val_loss=0.1736 \t val_acc=0.9699 \t time=64.62s\n",
      "=================================\n",
      "lr: 0.000125\n",
      "Epoch 21/30 \t loss=0.3861 \t val_loss=0.1684 \t val_acc=0.9671 \t time=63.91s\n",
      "=================================\n",
      "lr: 0.00011197638667498024\n",
      "Epoch 22/30 \t loss=0.3792 \t val_loss=0.1606 \t val_acc=0.9699 \t time=63.94s\n",
      "=================================\n",
      "lr: 9.934848925057487e-05\n",
      "Epoch 23/30 \t loss=0.3790 \t val_loss=0.1731 \t val_acc=0.9671 \t time=64.42s\n",
      "=================================\n",
      "lr: 8.750000000000001e-05\n",
      "Epoch 24/30 \t loss=0.3755 \t val_loss=0.1703 \t val_acc=0.9671 \t time=63.85s\n",
      "=================================\n",
      "lr: 7.679092927350956e-05\n",
      "Epoch 25/30 \t loss=0.3779 \t val_loss=0.1666 \t val_acc=0.9644 \t time=64.50s\n",
      "=================================\n",
      "lr: 6.754666676607666e-05\n",
      "Epoch 26/30 \t loss=0.3812 \t val_loss=0.1704 \t val_acc=0.9671 \t time=65.13s\n",
      "=================================\n",
      "lr: 6.004809471616712e-05\n",
      "Epoch 27/30 \t loss=0.3769 \t val_loss=0.1744 \t val_acc=0.9616 \t time=64.23s\n",
      "=================================\n",
      "lr: 5.4523053441056884e-05\n",
      "Epoch 28/30 \t loss=0.3733 \t val_loss=0.1702 \t val_acc=0.9671 \t time=64.76s\n",
      "=================================\n",
      "lr: 5.11394185240844e-05\n",
      "Epoch 29/30 \t loss=0.3717 \t val_loss=0.1700 \t val_acc=0.9671 \t time=64.62s\n",
      "=================================\n",
      "lr: 5e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30 \t loss=0.3740 \t val_loss=0.1732 \t val_acc=0.9671 \t time=64.58s\n",
      "=================================\n",
      "best loss: 0.14642868336776027 best accuracy: 0.9726027397260274\n",
      "\n",
      " ********** Fold 2 **********\n",
      "\n",
      "Loaded pretrained weights for efficientnet-b5\n",
      "lr: 5e-05\n",
      "Epoch 1/30 \t loss=1.3059 \t val_loss=0.9984 \t val_acc=0.7493 \t time=65.54s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.001\n",
      "Epoch 2/30 \t loss=0.7262 \t val_loss=0.3976 \t val_acc=0.8926 \t time=65.29s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.0009713539948733066\n",
      "Epoch 3/30 \t loss=0.6096 \t val_loss=0.3053 \t val_acc=0.9229 \t time=65.25s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.0008888711104815145\n",
      "Epoch 4/30 \t loss=0.5929 \t val_loss=0.2516 \t val_acc=0.9339 \t time=65.74s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.0007625\n",
      "Epoch 5/30 \t loss=0.5483 \t val_loss=0.2724 \t val_acc=0.9284 \t time=65.41s\n",
      "=================================\n",
      "lr: 0.000607482884391792\n",
      "Epoch 6/30 \t loss=0.4759 \t val_loss=0.2403 \t val_acc=0.9366 \t time=64.89s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.00044251711560820814\n",
      "Epoch 7/30 \t loss=0.5115 \t val_loss=0.2368 \t val_acc=0.9477 \t time=64.63s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.0002875000000000001\n",
      "Epoch 8/30 \t loss=0.4513 \t val_loss=0.2165 \t val_acc=0.9532 \t time=64.18s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.0001611288895184855\n",
      "Epoch 9/30 \t loss=0.4204 \t val_loss=0.2177 \t val_acc=0.9449 \t time=64.93s\n",
      "=================================\n",
      "lr: 7.864600512669355e-05\n",
      "Epoch 10/30 \t loss=0.4195 \t val_loss=0.2042 \t val_acc=0.9477 \t time=64.45s\n",
      "=================================\n",
      "lr: 5e-05\n",
      "Epoch 11/30 \t loss=0.4279 \t val_loss=0.2214 \t val_acc=0.9421 \t time=65.00s\n",
      "=================================\n",
      "lr: 0.0002\n",
      "Epoch 12/30 \t loss=0.4313 \t val_loss=0.2266 \t val_acc=0.9366 \t time=65.49s\n",
      "=================================\n",
      "lr: 0.00019886058147591563\n",
      "Epoch 13/30 \t loss=0.4088 \t val_loss=0.2036 \t val_acc=0.9504 \t time=65.58s\n",
      "=================================\n",
      "lr: 0.00019547694655894313\n",
      "Epoch 14/30 \t loss=0.4068 \t val_loss=0.2257 \t val_acc=0.9394 \t time=64.28s\n",
      "=================================\n",
      "lr: 0.00018995190528383292\n",
      "Epoch 15/30 \t loss=0.4093 \t val_loss=0.1961 \t val_acc=0.9477 \t time=64.33s\n",
      "=================================\n",
      "lr: 0.00018245333323392335\n",
      "Epoch 16/30 \t loss=0.4081 \t val_loss=0.2479 \t val_acc=0.9339 \t time=64.35s\n",
      "=================================\n",
      "lr: 0.00017320907072649046\n",
      "Epoch 17/30 \t loss=0.4063 \t val_loss=0.2492 \t val_acc=0.9311 \t time=64.90s\n",
      "=================================\n",
      "lr: 0.00016250000000000002\n",
      "Epoch 18/30 \t loss=0.4001 \t val_loss=0.2028 \t val_acc=0.9559 \t time=65.61s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.00015065151074942517\n",
      "Epoch 19/30 \t loss=0.3969 \t val_loss=0.1976 \t val_acc=0.9559 \t time=65.10s\n",
      "=================================\n",
      "lr: 0.0001380236133250198\n",
      "Epoch 20/30 \t loss=0.3953 \t val_loss=0.1991 \t val_acc=0.9477 \t time=65.00s\n",
      "=================================\n",
      "lr: 0.00012500000000000003\n",
      "Epoch 21/30 \t loss=0.3936 \t val_loss=0.2224 \t val_acc=0.9339 \t time=64.54s\n",
      "=================================\n",
      "lr: 0.00011197638667498024\n",
      "Epoch 22/30 \t loss=0.3834 \t val_loss=0.2037 \t val_acc=0.9477 \t time=65.03s\n",
      "=================================\n",
      "lr: 9.934848925057487e-05\n",
      "Epoch 23/30 \t loss=0.3824 \t val_loss=0.2058 \t val_acc=0.9504 \t time=65.13s\n",
      "=================================\n",
      "lr: 8.750000000000001e-05\n",
      "Epoch 24/30 \t loss=0.3857 \t val_loss=0.1927 \t val_acc=0.9504 \t time=65.24s\n",
      "=================================\n",
      "lr: 7.679092927350956e-05\n",
      "Epoch 25/30 \t loss=0.3737 \t val_loss=0.1921 \t val_acc=0.9559 \t time=64.73s\n",
      "=================================\n",
      "lr: 6.754666676607666e-05\n",
      "Epoch 26/30 \t loss=0.3708 \t val_loss=0.1947 \t val_acc=0.9504 \t time=66.11s\n",
      "=================================\n",
      "lr: 6.00480947161671e-05\n",
      "Epoch 27/30 \t loss=0.3827 \t val_loss=0.2000 \t val_acc=0.9504 \t time=66.41s\n",
      "=================================\n",
      "lr: 5.452305344105688e-05\n",
      "Epoch 28/30 \t loss=0.3722 \t val_loss=0.2025 \t val_acc=0.9504 \t time=64.35s\n",
      "=================================\n",
      "lr: 5.11394185240844e-05\n",
      "Epoch 29/30 \t loss=0.3727 \t val_loss=0.1991 \t val_acc=0.9532 \t time=64.41s\n",
      "=================================\n",
      "lr: 5e-05\n",
      "Epoch 30/30 \t loss=0.3769 \t val_loss=0.1922 \t val_acc=0.9532 \t time=64.50s\n",
      "=================================\n",
      "best loss: 0.19207834387603012 best accuracy: 0.9559228650137741\n",
      "\n",
      " ********** Fold 3 **********\n",
      "\n",
      "Loaded pretrained weights for efficientnet-b5\n",
      "lr: 5e-05\n",
      "Epoch 1/30 \t loss=1.2453 \t val_loss=0.3471 \t val_acc=0.9036 \t time=65.15s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.001\n",
      "Epoch 2/30 \t loss=0.7133 \t val_loss=0.2248 \t val_acc=0.9311 \t time=65.87s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.0009713539948733066\n",
      "Epoch 3/30 \t loss=0.5923 \t val_loss=0.2141 \t val_acc=0.9449 \t time=65.14s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.0008888711104815145\n",
      "Epoch 4/30 \t loss=0.5367 \t val_loss=0.2619 \t val_acc=0.9311 \t time=65.19s\n",
      "=================================\n",
      "lr: 0.0007625\n",
      "Epoch 5/30 \t loss=0.5304 \t val_loss=0.2333 \t val_acc=0.9311 \t time=65.66s\n",
      "=================================\n",
      "lr: 0.000607482884391792\n",
      "Epoch 6/30 \t loss=0.4821 \t val_loss=0.2317 \t val_acc=0.9449 \t time=64.96s\n",
      "=================================\n",
      "lr: 0.00044251711560820814\n",
      "Epoch 7/30 \t loss=0.4693 \t val_loss=0.1778 \t val_acc=0.9614 \t time=65.25s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.0002875000000000001\n",
      "Epoch 8/30 \t loss=0.4474 \t val_loss=0.1869 \t val_acc=0.9477 \t time=65.41s\n",
      "=================================\n",
      "lr: 0.0001611288895184855\n",
      "Epoch 9/30 \t loss=0.4165 \t val_loss=0.1637 \t val_acc=0.9532 \t time=64.71s\n",
      "=================================\n",
      "lr: 7.864600512669355e-05\n",
      "Epoch 10/30 \t loss=0.4282 \t val_loss=0.1538 \t val_acc=0.9669 \t time=64.68s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 5e-05\n",
      "Epoch 11/30 \t loss=0.4161 \t val_loss=0.1568 \t val_acc=0.9642 \t time=65.09s\n",
      "=================================\n",
      "lr: 0.0002\n",
      "Epoch 12/30 \t loss=0.4060 \t val_loss=0.1643 \t val_acc=0.9697 \t time=65.15s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.00019886058147591563\n",
      "Epoch 13/30 \t loss=0.4058 \t val_loss=0.1732 \t val_acc=0.9587 \t time=64.89s\n",
      "=================================\n",
      "lr: 0.00019547694655894313\n",
      "Epoch 14/30 \t loss=0.3917 \t val_loss=0.1730 \t val_acc=0.9587 \t time=64.72s\n",
      "=================================\n",
      "lr: 0.00018995190528383292\n",
      "Epoch 15/30 \t loss=0.4025 \t val_loss=0.1600 \t val_acc=0.9697 \t time=65.81s\n",
      "=================================\n",
      "lr: 0.00018245333323392335\n",
      "Epoch 16/30 \t loss=0.4111 \t val_loss=0.1935 \t val_acc=0.9587 \t time=65.25s\n",
      "=================================\n",
      "lr: 0.00017320907072649046\n",
      "Epoch 17/30 \t loss=0.3913 \t val_loss=0.1677 \t val_acc=0.9559 \t time=64.56s\n",
      "=================================\n",
      "lr: 0.00016250000000000002\n",
      "Epoch 18/30 \t loss=0.3998 \t val_loss=0.1584 \t val_acc=0.9697 \t time=64.65s\n",
      "=================================\n",
      "lr: 0.00015065151074942517\n",
      "Epoch 19/30 \t loss=0.3852 \t val_loss=0.1579 \t val_acc=0.9669 \t time=64.59s\n",
      "=================================\n",
      "lr: 0.0001380236133250198\n",
      "Epoch 20/30 \t loss=0.3846 \t val_loss=0.1525 \t val_acc=0.9725 \t time=64.92s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.00012500000000000003\n",
      "Epoch 21/30 \t loss=0.3898 \t val_loss=0.1507 \t val_acc=0.9780 \t time=65.35s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.00011197638667498024\n",
      "Epoch 22/30 \t loss=0.3821 \t val_loss=0.1485 \t val_acc=0.9697 \t time=65.12s\n",
      "=================================\n",
      "lr: 9.934848925057487e-05\n",
      "Epoch 23/30 \t loss=0.3742 \t val_loss=0.1644 \t val_acc=0.9587 \t time=65.58s\n",
      "=================================\n",
      "lr: 8.750000000000001e-05\n",
      "Epoch 24/30 \t loss=0.3737 \t val_loss=0.1554 \t val_acc=0.9587 \t time=65.16s\n",
      "=================================\n",
      "lr: 7.679092927350956e-05\n",
      "Epoch 25/30 \t loss=0.3734 \t val_loss=0.1497 \t val_acc=0.9614 \t time=64.75s\n",
      "=================================\n",
      "lr: 6.754666676607666e-05\n",
      "Epoch 26/30 \t loss=0.3825 \t val_loss=0.1457 \t val_acc=0.9669 \t time=64.64s\n",
      "=================================\n",
      "lr: 6.00480947161671e-05\n",
      "Epoch 27/30 \t loss=0.3718 \t val_loss=0.1551 \t val_acc=0.9587 \t time=65.01s\n",
      "=================================\n",
      "lr: 5.452305344105688e-05\n",
      "Epoch 28/30 \t loss=0.3704 \t val_loss=0.1579 \t val_acc=0.9614 \t time=64.92s\n",
      "=================================\n",
      "lr: 5.11394185240844e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30 \t loss=0.3712 \t val_loss=0.1569 \t val_acc=0.9614 \t time=64.41s\n",
      "=================================\n",
      "lr: 5e-05\n",
      "Epoch 30/30 \t loss=0.3709 \t val_loss=0.1507 \t val_acc=0.9614 \t time=65.26s\n",
      "=================================\n",
      "best loss: 0.14566902492357336 best accuracy: 0.977961432506887\n",
      "\n",
      " ********** Fold 4 **********\n",
      "\n",
      "Loaded pretrained weights for efficientnet-b5\n",
      "lr: 5e-05\n",
      "Epoch 1/30 \t loss=1.3115 \t val_loss=1.6796 \t val_acc=0.6860 \t time=65.90s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.001\n",
      "Epoch 2/30 \t loss=0.6773 \t val_loss=0.3689 \t val_acc=0.8871 \t time=65.43s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.0009713539948733066\n",
      "Epoch 3/30 \t loss=0.6012 \t val_loss=0.2419 \t val_acc=0.9229 \t time=66.12s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.0008888711104815145\n",
      "Epoch 4/30 \t loss=0.5428 \t val_loss=0.2467 \t val_acc=0.9339 \t time=65.78s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.0007625\n",
      "Epoch 5/30 \t loss=0.5260 \t val_loss=0.2413 \t val_acc=0.9339 \t time=65.26s\n",
      "=================================\n",
      "lr: 0.000607482884391792\n",
      "Epoch 6/30 \t loss=0.5185 \t val_loss=0.2563 \t val_acc=0.9256 \t time=65.13s\n",
      "=================================\n",
      "lr: 0.00044251711560820814\n",
      "Epoch 7/30 \t loss=0.5076 \t val_loss=0.1764 \t val_acc=0.9642 \t time=65.08s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.0002875000000000001\n",
      "Epoch 8/30 \t loss=0.4496 \t val_loss=0.1503 \t val_acc=0.9697 \t time=65.26s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.0001611288895184855\n",
      "Epoch 9/30 \t loss=0.4139 \t val_loss=0.1509 \t val_acc=0.9697 \t time=64.91s\n",
      "=================================\n",
      "lr: 7.864600512669355e-05\n",
      "Epoch 10/30 \t loss=0.4308 \t val_loss=0.1552 \t val_acc=0.9614 \t time=64.88s\n",
      "=================================\n",
      "lr: 5e-05\n",
      "Epoch 11/30 \t loss=0.4134 \t val_loss=0.1524 \t val_acc=0.9669 \t time=65.87s\n",
      "=================================\n",
      "lr: 0.0002\n",
      "Epoch 12/30 \t loss=0.4169 \t val_loss=0.1525 \t val_acc=0.9697 \t time=66.11s\n",
      "=================================\n",
      "lr: 0.00019886058147591563\n",
      "Epoch 13/30 \t loss=0.4121 \t val_loss=0.1480 \t val_acc=0.9614 \t time=65.91s\n",
      "=================================\n",
      "lr: 0.00019547694655894313\n",
      "Epoch 14/30 \t loss=0.4074 \t val_loss=0.1745 \t val_acc=0.9532 \t time=64.84s\n",
      "=================================\n",
      "lr: 0.00018995190528383292\n",
      "Epoch 15/30 \t loss=0.4021 \t val_loss=0.1438 \t val_acc=0.9614 \t time=66.17s\n",
      "=================================\n",
      "lr: 0.00018245333323392335\n",
      "Epoch 16/30 \t loss=0.4010 \t val_loss=0.1620 \t val_acc=0.9697 \t time=65.01s\n",
      "=================================\n",
      "lr: 0.00017320907072649046\n",
      "Epoch 17/30 \t loss=0.3927 \t val_loss=0.1457 \t val_acc=0.9725 \t time=65.01s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.00016250000000000002\n",
      "Epoch 18/30 \t loss=0.3902 \t val_loss=0.1595 \t val_acc=0.9669 \t time=65.52s\n",
      "=================================\n",
      "lr: 0.00015065151074942517\n",
      "Epoch 19/30 \t loss=0.3876 \t val_loss=0.1334 \t val_acc=0.9752 \t time=64.86s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.0001380236133250198\n",
      "Epoch 20/30 \t loss=0.3895 \t val_loss=0.1303 \t val_acc=0.9780 \t time=64.93s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.00012500000000000003\n",
      "Epoch 21/30 \t loss=0.3858 \t val_loss=0.1357 \t val_acc=0.9752 \t time=65.87s\n",
      "=================================\n",
      "lr: 0.00011197638667498024\n",
      "Epoch 22/30 \t loss=0.3841 \t val_loss=0.1331 \t val_acc=0.9835 \t time=64.76s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 9.934848925057487e-05\n",
      "Epoch 23/30 \t loss=0.3785 \t val_loss=0.1401 \t val_acc=0.9697 \t time=64.84s\n",
      "=================================\n",
      "lr: 8.750000000000001e-05\n",
      "Epoch 24/30 \t loss=0.3767 \t val_loss=0.1472 \t val_acc=0.9725 \t time=65.79s\n",
      "=================================\n",
      "lr: 7.679092927350956e-05\n",
      "Epoch 25/30 \t loss=0.3774 \t val_loss=0.1463 \t val_acc=0.9725 \t time=64.79s\n",
      "=================================\n",
      "lr: 6.754666676607666e-05\n",
      "Epoch 26/30 \t loss=0.3717 \t val_loss=0.1464 \t val_acc=0.9697 \t time=65.55s\n",
      "=================================\n",
      "lr: 6.00480947161671e-05\n",
      "Epoch 27/30 \t loss=0.3758 \t val_loss=0.1546 \t val_acc=0.9725 \t time=65.65s\n",
      "=================================\n",
      "lr: 5.452305344105688e-05\n",
      "Epoch 28/30 \t loss=0.3734 \t val_loss=0.1555 \t val_acc=0.9725 \t time=64.67s\n",
      "=================================\n",
      "lr: 5.11394185240844e-05\n",
      "Epoch 29/30 \t loss=0.3694 \t val_loss=0.1480 \t val_acc=0.9697 \t time=64.85s\n",
      "=================================\n",
      "lr: 5e-05\n",
      "Epoch 30/30 \t loss=0.3735 \t val_loss=0.1495 \t val_acc=0.9725 \t time=66.15s\n",
      "=================================\n",
      "best loss: 0.13030515740747037 best accuracy: 0.9834710743801653\n",
      "CV loss:0.149175 \t CV accuracy:0.973632\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log = open('./exp/exp' + str(EXP) +'/log.txt', 'w')\n",
    "log.write('IMG_SIZE%d\\n'%IMG_SIZE)\n",
    "log.write('SEED%d\\n'%SEED)\n",
    "cv_losses = []\n",
    "cv_metrics = []\n",
    "\n",
    "for fold in range(FOLD):\n",
    "    print('\\n ********** Fold %d **********\\n'%fold)\n",
    "    ###################### Dataset #######################\n",
    "    trainset     = PlantDataset(train_df.iloc[tr_idx[fold]].reset_index(), transform =train_transform_advprop)\n",
    "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "\n",
    "    valset       = PlantDataset(train_df.iloc[val_idx[fold]].reset_index(), transform   =test_transform)\n",
    "    val_loader   = torch.utils.data.DataLoader(valset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "    ####################### Model ########################\n",
    "    model_conv = EfficientNet.from_pretrained(\"efficientnet-b5\", advprop=True)\n",
    "    model_conv._dropout = nn.Dropout(p=0.5)\n",
    "    model_conv._avg_pooling = AdaptiveConcatPool2d()\n",
    "    model_conv._fc = nn.Sequential(nn.Linear(2048*2,256), Mish(), nn.Dropout(p=0.5), nn.Linear(256,4))\n",
    "    model_conv.cuda()\n",
    "\n",
    "    ###################### Optim ########################\n",
    "    optimizer = torch.optim.AdamW(model_conv.parameters(), lr=LR/25., weight_decay=1e-4)\n",
    "\n",
    "    criterion = LSR()\n",
    "    criterion_test = nn.CrossEntropyLoss()\n",
    "\n",
    "    T = len(train_loader)//ACCUMULATE * 20 # cycle\n",
    "    scheduler = CosineAnnealingWarmUpRestarts(optimizer, T_0=T, T_mult=1, eta_max=LR, T_up=T//20, gamma=0.2)\n",
    "    scheduler.step()\n",
    "\n",
    "    model_conv, optimizer = amp.initialize(model_conv, optimizer, opt_level=\"O1\",verbosity=0)\n",
    "    \n",
    "    val_loss, val_acc = train(fold)\n",
    "    \n",
    "    cv_losses.append(val_loss)\n",
    "    cv_metrics.append(val_acc)\n",
    "    log.write('[Flod%d] val loss:%.5f \\t val acc:%.5f; \\n'%(fold, val_loss, val_acc))\n",
    "\n",
    "cv_loss = sum(cv_losses)/FOLD   \n",
    "cv_acc = sum(cv_metrics)/FOLD   \n",
    "print('CV loss:%.6f \\t CV accuracy:%.6f'%(cv_loss, cv_acc))\n",
    "log.write('CV loss:%.6f \\t CV accuracy:%.6f'%(cv_loss, cv_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./exp/exp3/pipeline.ipynb'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.copyfile('./pipeline-ls.ipynb', './exp/exp' + str(EXP) + '/pipeline.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
