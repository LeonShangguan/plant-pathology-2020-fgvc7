{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import isfile\n",
    "import torch.nn.init as init\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from PIL import Image, ImageFilter\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, LabelEncoder, OneHotEncoder\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from torch.optim import Adam, SGD, RMSprop\n",
    "import time\n",
    "import math\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.autograd import Variable\n",
    "import torch.functional as F\n",
    "from tqdm import tqdm\n",
    "from sklearn import metrics\n",
    "import urllib\n",
    "import pickle\n",
    "import cv2\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "import seaborn as sns\n",
    "import random\n",
    "import sys\n",
    "import shutil\n",
    "import albumentations\n",
    "from albumentations import pytorch as AT\n",
    "from pytorchcv.model_provider import get_model as ptcv_get_model\n",
    "\n",
    "\n",
    "from apex import amp\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "\n",
    "from torchcontrib.optim import SWA\n",
    "\n",
    "# torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.special\n",
    "\n",
    "SEED = 42\n",
    "base_dir = '../plant-pathology-2020-fgvc7'\n",
    "def seed_everything(seed=SEED):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYHTONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_everything(SEED)\n",
    "\n",
    "def l2_norm(input,axis=1):\n",
    "    norm = torch.norm(input,2,axis,True)\n",
    "    output = torch.div(input, norm)\n",
    "    return output\n",
    "\n",
    "sigmoid = lambda x: scipy.special.expit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize tools\n",
    "def visualize(**images):\n",
    "    \"\"\"PLot images in one row.\"\"\"\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(16, 5))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image)\n",
    "    plt.show()\n",
    "    \n",
    "def test_transform(img_path, transform):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = transform(image = img)['image']\n",
    "    visualize(image = img)\n",
    "    \n",
    "def write_aug(img_path, transform, num=30):\n",
    "    img = cv2.imread(img_path)\n",
    "    for i in range(num):\n",
    "        t = transform(image = img)['image']\n",
    "        cv2.imwrite('./aug/'+str(i)+'.jpg',t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD = 5\n",
    "BATCH_SIZE = 8  ## batch size * accumulate ~= 64 (64x1, 32x2, 24x3, 16*4)\n",
    "ACCUMULATE = 4\n",
    "LR = 1e-3\n",
    "EPOCH = 20\n",
    "IMG_SIZE = 384  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP = 1\n",
    "while os.path.exists('./exp/exp%d'%EXP):\n",
    "    EXP+=1\n",
    "os.makedirs('./exp/exp%d'%EXP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv( base_dir + '/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>healthy</th>\n",
       "      <th>multiple_diseases</th>\n",
       "      <th>rust</th>\n",
       "      <th>scab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Train_1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Train_2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Train_3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Train_4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_id  healthy  multiple_diseases  rust  scab\n",
       "0  Train_0        0                  0     0     1\n",
       "1  Train_1        0                  1     0     0\n",
       "2  Train_2        1                  0     0     0\n",
       "3  Train_3        0                  0     1     0\n",
       "4  Train_4        1                  0     0     0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlantDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.df = dataframe\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        row = self.df.iloc[idx]\n",
    "        label = np.argmax([row.healthy, row.multiple_diseases, row.rust, row.scab])\n",
    "#         if label[1] == 1: # fix anno bug in label (should post process to recover raw label)\n",
    "#             label[2] = 1\n",
    "#             label[3] = 1\n",
    "#         label = np.array(label)\n",
    "\n",
    "        path = base_dir + '/images/' + row.image_id + '.jpg'\n",
    "        image = cv2.imread(path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image=image)\n",
    "            \n",
    "        image = image['image']\n",
    "            \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leon/anaconda3/envs/leon/lib/python3.7/site-packages/albumentations/augmentations/transforms.py:2908: UserWarning: Using lambda is incompatible with multiprocessing. Consider using regular functions or partial().\n",
      "  \"Using lambda is incompatible with multiprocessing. \"\n"
     ]
    }
   ],
   "source": [
    "def pre_trans(x, cols, rows):\n",
    "    return (x * 2.0 - 1.0)\n",
    "\n",
    "train_transform_advprop = albumentations.Compose([\n",
    "    albumentations.Resize(IMG_SIZE, IMG_SIZE),\n",
    "    albumentations.RandomRotate90(p=0.5),\n",
    "    albumentations.Transpose(p=0.5),\n",
    "    albumentations.Flip(p=0.5),\n",
    "    albumentations.OneOf([\n",
    "        albumentations.RandomBrightness(0.15, p=1), \n",
    "        albumentations.RandomContrast(0.15, p=1),\n",
    "        albumentations.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=20, p=1),\n",
    "    ], p=0.5), \n",
    "    albumentations.OneOf([\n",
    "        albumentations.ISONoise(color_shift=(0.01, 0.03), intensity=(0.1, 0.3)),\n",
    "        albumentations.IAASharpen(alpha=(0.1, 0.3), lightness=(0.5, 1.0)),\n",
    "    ], p=0.5), \n",
    "    albumentations.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.2, rotate_limit=45, border_mode=1, p=0.5),\n",
    "    albumentations.Lambda(image = pre_trans),\n",
    "    AT.ToTensor(),\n",
    "    ])\n",
    "\n",
    "\n",
    "test_transform = albumentations.Compose([\n",
    "    albumentations.Resize(IMG_SIZE, IMG_SIZE),\n",
    "    albumentations.Lambda(image = pre_trans),\n",
    "    AT.ToTensor(),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1456 | test: 365\n",
      "Train: 1457 | test: 364\n",
      "Train: 1457 | test: 364\n",
      "Train: 1457 | test: 364\n",
      "Train: 1457 | test: 364\n"
     ]
    }
   ],
   "source": [
    "sfolder = StratifiedKFold(n_splits=FOLD,random_state=SEED,shuffle=True)\n",
    "\n",
    "tr_idx = []\n",
    "val_idx = []\n",
    "\n",
    "Y = np.array(train_df[['healthy','multiple_diseases','rust','scab']])\n",
    "Y = np.argmax(Y, axis=1)\n",
    "\n",
    "for train, val in sfolder.split(range(len(train_df)), Y):\n",
    "    tr_idx.append(train)\n",
    "    val_idx.append(val)\n",
    "    print('Train: %s | test: %s' % (len(train), len(val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.ranger import RangerVA \n",
    "from utils.lr_scheduler import CosineAnnealingWarmUpRestarts\n",
    "from utils.label_smooth import LSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class smooth_L1_ohem(nn.Module):\n",
    "    def __init__(self, top_k=0.5):\n",
    "        super(smooth_L1_ohem, self).__init__()\n",
    "        self.top_k = top_k\n",
    "        self.loss = nn.SmoothL1Loss(reduction='none')\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        loss = self.loss(input, target)\n",
    "        if self.top_k == 1:\n",
    "            return torch.mean(loss)\n",
    "        else:\n",
    "            valid_loss, idxs = torch.topk(loss, int(self.top_k * loss.size()[0]), dim=0)    \n",
    "            return torch.mean(valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaptiveConcatPool2d(nn.Module):\n",
    "    def __init__(self, sz=None):\n",
    "        super().__init__()\n",
    "        sz = sz or (1,1)\n",
    "        self.ap = nn.AdaptiveAvgPool2d(sz)\n",
    "        self.mp = nn.AdaptiveMaxPool2d(sz)\n",
    "    def forward(self, x):\n",
    "        return torch.cat([self.mp(x), self.ap(x)], 1)\n",
    "    \n",
    "def mish(input):\n",
    "    return input * torch.tanh(F.softplus(input))\n",
    "       \n",
    "class Mish(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, input):\n",
    "        return mish(input)\n",
    "\n",
    "def gem(x, p=3, eps=1e-6):\n",
    "    return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\n",
    "\n",
    "class GeM(nn.Module):\n",
    "    def __init__(self, p=3, eps=1e-6):\n",
    "        super(GeM,self).__init__()\n",
    "        self.p = Parameter(torch.ones(1)*p)\n",
    "        self.eps = eps\n",
    "    def forward(self, x):\n",
    "        return gem(x, p=self.p, eps=self.eps)       \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + ', ' + 'eps=' + str(self.eps) + ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epoch):\n",
    "    model_conv.train()         \n",
    "    avg_loss = 0.\n",
    "    optimizer.zero_grad()\n",
    "    for idx, (imgs, labels) in enumerate(train_loader):\n",
    "        imgs_train, labels_train = imgs.cuda(), labels.cuda()\n",
    "        output_train = model_conv(imgs_train)\n",
    "        loss = criterion(output_train,labels_train)\n",
    "        #loss.backward()\n",
    "        with amp.scale_loss(loss/ACCUMULATE, optimizer) as scaled_loss:\n",
    "            scaled_loss.backward()\n",
    "        if ((idx+1)%ACCUMULATE==0):\n",
    "            torch.nn.utils.clip_grad_norm_(model_conv.parameters(), max_norm=5.0, norm_type=2)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            scheduler.step()\n",
    "        avg_loss += loss.item() / len(train_loader)  \n",
    "    return avg_loss\n",
    "\n",
    "def test_model():    \n",
    "    avg_val_loss = 0.\n",
    "    model_conv.eval()\n",
    "    y_pred_val = np.zeros((len(valset), 4))\n",
    "    y_true_val = np.zeros((len(valset)))\n",
    "    with torch.no_grad():\n",
    "        for idx, (imgs, labels) in enumerate(val_loader):\n",
    "            imgs_vaild, labels_vaild = imgs.cuda(), labels.cuda()\n",
    "            output_test = model_conv(imgs_vaild)\n",
    "            avg_val_loss += (criterion_test(output_test, labels_vaild).item() / len(val_loader)) \n",
    "            a = labels_vaild.detach().cpu().numpy().astype(np.int) #.reshape(-1,4)\n",
    "            b = output_test.detach().cpu().numpy() #.reshape(-1,4)\n",
    "\n",
    "            y_pred_val[idx*BATCH_SIZE:idx*BATCH_SIZE+b.shape[0]] = b\n",
    "            y_true_val[idx*BATCH_SIZE:idx*BATCH_SIZE+b.shape[0]] = a\n",
    "            \n",
    "    acc = sum(np.argmax(y_pred_val, axis=1) == y_true_val) / len(y_pred_val)\n",
    "\n",
    "    return avg_val_loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(fold):\n",
    "    best_avg_loss = 100.0 \n",
    "    best_acc = 0.0\n",
    "\n",
    "    ### training\n",
    "    for epoch in range(EPOCH):   \n",
    "        print('lr:', scheduler.get_lr()[0]) \n",
    "        start_time        = time.time()\n",
    "        avg_loss          = train_model(epoch)\n",
    "        avg_val_loss, acc = test_model()\n",
    "        elapsed_time      = time.time() - start_time \n",
    "        print('Epoch {}/{} \\t loss={:.4f} \\t val_loss={:.4f} \\t val_acc={:.4f} \\t time={:.2f}s'.format(\n",
    "            epoch + 1, EPOCH, avg_loss, avg_val_loss, acc, elapsed_time))\n",
    "\n",
    "        if avg_val_loss < best_avg_loss:\n",
    "            best_avg_loss = avg_val_loss\n",
    "            \n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            torch.save(model_conv.state_dict(), './exp/exp' + str(EXP) + '/efficientnet-b5-best' + str(fold) + '.pth')\n",
    "            print('model saved!')\n",
    "\n",
    "        print('=================================')   \n",
    "\n",
    "    print('best loss:', best_avg_loss, 'best accuracy:', best_acc)\n",
    "    \n",
    "    return best_avg_loss, best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ********** Fold 0 **********\n",
      "\n",
      "lr: 6.133333333333334e-05\n",
      "Epoch 1/20 \t loss=0.8269 \t val_loss=0.4924 \t val_acc=0.8603 \t time=88.43s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.0009999967597518673\n",
      "Epoch 2/20 \t loss=0.7137 \t val_loss=0.5062 \t val_acc=0.8849 \t time=95.87s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.000993159934564823\n",
      "Epoch 3/20 \t loss=0.6096 \t val_loss=0.2620 \t val_acc=0.9479 \t time=97.89s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.0009734165397987437\n",
      "Epoch 4/20 \t loss=0.5746 \t val_loss=0.2852 \t val_acc=0.9233 \t time=97.17s\n",
      "=================================\n",
      "lr: 0.0009413051237956595\n",
      "Epoch 5/20 \t loss=0.5885 \t val_loss=0.3592 \t val_acc=0.9123 \t time=92.37s\n",
      "=================================\n",
      "lr: 0.0008977016022759204\n",
      "Epoch 6/20 \t loss=0.5769 \t val_loss=0.3357 \t val_acc=0.9288 \t time=93.00s\n",
      "=================================\n",
      "lr: 0.0008437953656406874\n",
      "Epoch 7/20 \t loss=0.5575 \t val_loss=0.2988 \t val_acc=0.9315 \t time=91.75s\n",
      "=================================\n",
      "lr: 0.0007810568355022987\n",
      "Epoch 8/20 \t loss=0.5422 \t val_loss=0.2831 \t val_acc=0.9288 \t time=92.38s\n",
      "=================================\n",
      "lr: 0.0007111973554157874\n",
      "Epoch 9/20 \t loss=0.5214 \t val_loss=0.2556 \t val_acc=0.9397 \t time=92.62s\n",
      "=================================\n",
      "lr: 0.0006361225098878405\n",
      "Epoch 10/20 \t loss=0.5330 \t val_loss=0.2614 \t val_acc=0.9397 \t time=92.10s\n",
      "=================================\n",
      "lr: 0.0005578801449989446\n",
      "Epoch 11/20 \t loss=0.5054 \t val_loss=0.2473 \t val_acc=0.9425 \t time=92.90s\n",
      "=================================\n",
      "lr: 0.0004786045085006453\n",
      "Epoch 12/20 \t loss=0.4769 \t val_loss=0.2130 \t val_acc=0.9479 \t time=91.33s\n",
      "=================================\n",
      "lr: 0.00040045803310045604\n",
      "Epoch 13/20 \t loss=0.4615 \t val_loss=0.2285 \t val_acc=0.9452 \t time=91.64s\n",
      "=================================\n",
      "lr: 0.0003255723509346361\n"
     ]
    }
   ],
   "source": [
    "log = open('./exp/exp' + str(EXP) +'/log.txt', 'w')\n",
    "log.write('IMG_SIZE%d\\n'%IMG_SIZE)\n",
    "log.write('SEED%d\\n'%SEED)\n",
    "cv_losses = []\n",
    "cv_metrics = []\n",
    "\n",
    "for fold in range(FOLD):\n",
    "    print('\\n ********** Fold %d **********\\n'%fold)\n",
    "    ###################### Dataset #######################\n",
    "    trainset     = PlantDataset(train_df.iloc[tr_idx[fold]].reset_index(), transform =train_transform_advprop)\n",
    "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "\n",
    "    valset       = PlantDataset(train_df.iloc[val_idx[fold]].reset_index(), transform   =test_transform)\n",
    "    val_loader   = torch.utils.data.DataLoader(valset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "    ####################### Model ########################\n",
    "#     model_conv = EfficientNet.from_pretrained(\"efficientnet-b5\", advprop=True)\n",
    "    model_conv = ptcv_get_model(\"seresnext101_32x4d\", pretrained=True)\n",
    "#     model_conv._dropout = nn.Dropout(p=0.5)\n",
    "#     model_conv._avg_pooling = AdaptiveConcatPool2d(1)\n",
    "    model_conv.features.final_pool = nn.AdaptiveAvgPool2d(1)\n",
    "#     model_conv._fc = nn.Sequential(nn.Linear(2048*2,256), Mish(), nn.Dropout(p=0.5), nn.Linear(256,4))\n",
    "    model_conv.output = nn.Sequential(nn.Linear(2048,256), Mish(), nn.Dropout(p=0.5), nn.Linear(256,4))\n",
    "    model_conv.cuda()\n",
    "\n",
    "    ###################### Optim ########################\n",
    "    optimizer = torch.optim.AdamW(model_conv.parameters(), lr=LR/25., weight_decay=1e-4)\n",
    "\n",
    "    criterion = LSR()\n",
    "    criterion_test = nn.CrossEntropyLoss()\n",
    "\n",
    "    T = len(train_loader)//ACCUMULATE * 20 # cycle\n",
    "    scheduler = CosineAnnealingWarmUpRestarts(optimizer, T_0=T, T_mult=1, eta_max=LR, T_up=T//20, gamma=0.2)\n",
    "    scheduler.step()\n",
    "\n",
    "    model_conv, optimizer = amp.initialize(model_conv, optimizer, opt_level=\"O1\",verbosity=0)\n",
    "    \n",
    "    val_loss, val_acc = train(fold)\n",
    "    \n",
    "    cv_losses.append(val_loss)\n",
    "    cv_metrics.append(val_acc)\n",
    "    log.write('[Flod%d] val loss:%.5f \\t val acc:%.5f; \\n'%(fold, val_loss, val_acc))\n",
    "\n",
    "cv_loss = sum(cv_losses)/FOLD   \n",
    "cv_acc = sum(cv_metrics)/FOLD   \n",
    "print('CV loss:%.6f \\t CV accuracy:%.6f'%(cv_loss, cv_acc))\n",
    "log.write('CV loss:%.6f \\t CV accuracy:%.6f'%(cv_loss, cv_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./exp/exp3/pipeline.ipynb'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.copyfile('./pipeline-ls.ipynb', './exp/exp' + str(EXP) + '/pipeline.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
