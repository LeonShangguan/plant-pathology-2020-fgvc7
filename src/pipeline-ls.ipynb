{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import isfile\n",
    "import torch.nn.init as init\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from PIL import Image, ImageFilter\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, LabelEncoder, OneHotEncoder\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from torch.optim import Adam, SGD, RMSprop\n",
    "import time\n",
    "import math\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.autograd import Variable\n",
    "import torch.functional as F\n",
    "from tqdm import tqdm\n",
    "from sklearn import metrics\n",
    "import urllib\n",
    "import pickle\n",
    "import cv2\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "import seaborn as sns\n",
    "import random\n",
    "import sys\n",
    "import shutil\n",
    "import albumentations\n",
    "from albumentations import pytorch as AT\n",
    "from pytorchcv.model_provider import get_model as ptcv_get_model\n",
    "\n",
    "\n",
    "from apex import amp\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "\n",
    "from torchcontrib.optim import SWA\n",
    "\n",
    "# torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.special\n",
    "\n",
    "SEED = 42\n",
    "base_dir = '../plant-pathology-2020-fgvc7'\n",
    "def seed_everything(seed=SEED):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYHTONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_everything(SEED)\n",
    "\n",
    "def l2_norm(input,axis=1):\n",
    "    norm = torch.norm(input,2,axis,True)\n",
    "    output = torch.div(input, norm)\n",
    "    return output\n",
    "\n",
    "sigmoid = lambda x: scipy.special.expit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize tools\n",
    "def visualize(**images):\n",
    "    \"\"\"PLot images in one row.\"\"\"\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(16, 5))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image)\n",
    "    plt.show()\n",
    "    \n",
    "def test_transform(img_path, transform):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = transform(image = img)['image']\n",
    "    visualize(image = img)\n",
    "    \n",
    "def write_aug(img_path, transform, num=30):\n",
    "    img = cv2.imread(img_path)\n",
    "    for i in range(num):\n",
    "        t = transform(image = img)['image']\n",
    "        cv2.imwrite('./aug/'+str(i)+'.jpg',t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD = 5\n",
    "BATCH_SIZE = 12  ## batch size * accumulate ~= 64 (64x1, 32x2, 24x3, 16*4)\n",
    "ACCUMULATE = 2\n",
    "LR = 1e-3\n",
    "EPOCH = 40\n",
    "IMG_SIZE = 384  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP = 1\n",
    "while os.path.exists('./exp/exp%d'%EXP):\n",
    "    EXP+=1\n",
    "os.makedirs('./exp/exp%d'%EXP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv( base_dir + '/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>healthy</th>\n",
       "      <th>multiple_diseases</th>\n",
       "      <th>rust</th>\n",
       "      <th>scab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Train_1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Train_2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Train_3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Train_4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_id  healthy  multiple_diseases  rust  scab\n",
       "0  Train_0        0                  0     0     1\n",
       "1  Train_1        0                  1     0     0\n",
       "2  Train_2        1                  0     0     0\n",
       "3  Train_3        0                  0     1     0\n",
       "4  Train_4        1                  0     0     0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlantDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.df = dataframe\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        row = self.df.iloc[idx]\n",
    "        label = np.argmax([row.healthy, row.multiple_diseases, row.rust, row.scab])\n",
    "#         if label[1] == 1: # fix anno bug in label (should post process to recover raw label)\n",
    "#             label[2] = 1\n",
    "#             label[3] = 1\n",
    "#         label = np.array(label)\n",
    "\n",
    "        path = base_dir + '/images/' + row.image_id + '.jpg'\n",
    "        image = cv2.imread(path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image=image)\n",
    "            \n",
    "        image = image['image']\n",
    "            \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leon/anaconda3/envs/leon/lib/python3.7/site-packages/albumentations/augmentations/transforms.py:2908: UserWarning: Using lambda is incompatible with multiprocessing. Consider using regular functions or partial().\n",
      "  \"Using lambda is incompatible with multiprocessing. \"\n"
     ]
    }
   ],
   "source": [
    "def pre_trans(x, cols, rows):\n",
    "    return (x * 2.0 - 1.0)\n",
    "\n",
    "train_transform_advprop = albumentations.Compose([\n",
    "    albumentations.Resize(IMG_SIZE, IMG_SIZE),\n",
    "    albumentations.RandomRotate90(p=0.5),\n",
    "    albumentations.Transpose(p=0.5),\n",
    "    albumentations.Flip(p=0.5),\n",
    "    albumentations.OneOf([\n",
    "        albumentations.RandomBrightness(0.15, p=1), \n",
    "        albumentations.RandomContrast(0.15, p=1),\n",
    "        albumentations.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=20, p=1),\n",
    "    ], p=0.5), \n",
    "    albumentations.OneOf([\n",
    "        albumentations.ISONoise(color_shift=(0.01, 0.03), intensity=(0.1, 0.3)),\n",
    "        albumentations.IAASharpen(alpha=(0.1, 0.3), lightness=(0.5, 1.0)),\n",
    "    ], p=0.5), \n",
    "    albumentations.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.2, rotate_limit=45, border_mode=1, p=0.5),\n",
    "    albumentations.Lambda(image = pre_trans),\n",
    "    AT.ToTensor(),\n",
    "    ])\n",
    "\n",
    "\n",
    "test_transform = albumentations.Compose([\n",
    "    albumentations.Resize(IMG_SIZE, IMG_SIZE),\n",
    "    albumentations.Lambda(image = pre_trans),\n",
    "    AT.ToTensor(),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1456 | test: 365\n",
      "Train: 1457 | test: 364\n",
      "Train: 1457 | test: 364\n",
      "Train: 1457 | test: 364\n",
      "Train: 1457 | test: 364\n"
     ]
    }
   ],
   "source": [
    "sfolder = StratifiedKFold(n_splits=FOLD,random_state=SEED,shuffle=True)\n",
    "\n",
    "tr_idx = []\n",
    "val_idx = []\n",
    "\n",
    "Y = np.array(train_df[['healthy','multiple_diseases','rust','scab']])\n",
    "Y = np.argmax(Y, axis=1)\n",
    "\n",
    "for train, val in sfolder.split(range(len(train_df)), Y):\n",
    "    tr_idx.append(train)\n",
    "    val_idx.append(val)\n",
    "    print('Train: %s | test: %s' % (len(train), len(val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.ranger import RangerVA \n",
    "from utils.lr_scheduler import CosineAnnealingWarmUpRestarts\n",
    "from utils.label_smooth import LSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class smooth_L1_ohem(nn.Module):\n",
    "    def __init__(self, top_k=0.5):\n",
    "        super(smooth_L1_ohem, self).__init__()\n",
    "        self.top_k = top_k\n",
    "        self.loss = nn.SmoothL1Loss(reduction='none')\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        loss = self.loss(input, target)\n",
    "        if self.top_k == 1:\n",
    "            return torch.mean(loss)\n",
    "        else:\n",
    "            valid_loss, idxs = torch.topk(loss, int(self.top_k * loss.size()[0]), dim=0)    \n",
    "            return torch.mean(valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaptiveConcatPool2d(nn.Module):\n",
    "    def __init__(self, sz=None):\n",
    "        super().__init__()\n",
    "        sz = sz or (1,1)\n",
    "        self.ap = nn.AdaptiveAvgPool2d(sz)\n",
    "        self.mp = nn.AdaptiveMaxPool2d(sz)\n",
    "    def forward(self, x):\n",
    "        return torch.cat([self.mp(x), self.ap(x)], 1)\n",
    "    \n",
    "def mish(input):\n",
    "    return input * torch.tanh(F.softplus(input))\n",
    "       \n",
    "class Mish(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, input):\n",
    "        return mish(input)\n",
    "\n",
    "def gem(x, p=3, eps=1e-6):\n",
    "    return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\n",
    "\n",
    "class GeM(nn.Module):\n",
    "    def __init__(self, p=3, eps=1e-6):\n",
    "        super(GeM,self).__init__()\n",
    "        self.p = Parameter(torch.ones(1)*p)\n",
    "        self.eps = eps\n",
    "    def forward(self, x):\n",
    "        return gem(x, p=self.p, eps=self.eps)       \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + ', ' + 'eps=' + str(self.eps) + ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epoch):\n",
    "    model_conv.train()         \n",
    "    avg_loss = 0.\n",
    "    optimizer.zero_grad()\n",
    "    for idx, (imgs, labels) in enumerate(train_loader):\n",
    "        imgs_train, labels_train = imgs.cuda(), labels.cuda()\n",
    "        output_train = model_conv(imgs_train)\n",
    "        loss = criterion(output_train,labels_train)\n",
    "        #loss.backward()\n",
    "        with amp.scale_loss(loss/ACCUMULATE, optimizer) as scaled_loss:\n",
    "            scaled_loss.backward()\n",
    "        if ((idx+1)%ACCUMULATE==0):\n",
    "            torch.nn.utils.clip_grad_norm_(model_conv.parameters(), max_norm=5.0, norm_type=2)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            scheduler.step()\n",
    "        avg_loss += loss.item() / len(train_loader)  \n",
    "    return avg_loss\n",
    "\n",
    "def test_model():    \n",
    "    avg_val_loss = 0.\n",
    "    model_conv.eval()\n",
    "    y_pred_val = np.zeros((len(valset), 4))\n",
    "    y_true_val = np.zeros((len(valset)))\n",
    "    with torch.no_grad():\n",
    "        for idx, (imgs, labels) in enumerate(val_loader):\n",
    "            imgs_vaild, labels_vaild = imgs.cuda(), labels.cuda()\n",
    "            output_test = model_conv(imgs_vaild)\n",
    "            avg_val_loss += (criterion_test(output_test, labels_vaild).item() / len(val_loader)) \n",
    "            a = labels_vaild.detach().cpu().numpy().astype(np.int) #.reshape(-1,4)\n",
    "            b = output_test.detach().cpu().numpy() #.reshape(-1,4)\n",
    "\n",
    "            y_pred_val[idx*BATCH_SIZE:idx*BATCH_SIZE+b.shape[0]] = b\n",
    "            y_true_val[idx*BATCH_SIZE:idx*BATCH_SIZE+b.shape[0]] = a\n",
    "            \n",
    "    acc = sum(np.argmax(y_pred_val, axis=1) == y_true_val) / len(y_pred_val)\n",
    "\n",
    "    return avg_val_loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(fold):\n",
    "    best_avg_loss = 100.0 \n",
    "    best_acc = 0.0\n",
    "\n",
    "    ### training\n",
    "    for epoch in range(EPOCH):   \n",
    "        print('lr:', scheduler.get_lr()[0]) \n",
    "        start_time        = time.time()\n",
    "        avg_loss          = train_model(epoch)\n",
    "        avg_val_loss, acc = test_model()\n",
    "        elapsed_time      = time.time() - start_time \n",
    "        print('Epoch {}/{} \\t loss={:.4f} \\t val_loss={:.4f} \\t val_acc={:.4f} \\t time={:.2f}s'.format(\n",
    "            epoch + 1, EPOCH, avg_loss, avg_val_loss, acc, elapsed_time))\n",
    "\n",
    "        if avg_val_loss < best_avg_loss:\n",
    "            best_avg_loss = avg_val_loss\n",
    "            \n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            torch.save(model_conv.state_dict(), './exp/exp' + str(EXP) + '/efficientnet-b5-best' + str(fold) + '.pth')\n",
    "            print('model saved!')\n",
    "\n",
    "        print('=================================')   \n",
    "\n",
    "    print('best loss:', best_avg_loss, 'best accuracy:', best_acc)\n",
    "    \n",
    "    return best_avg_loss, best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ********** Fold 0 **********\n",
      "\n",
      "lr: 5.573770491803279e-05\n",
      "Epoch 1/40 \t loss=0.8060 \t val_loss=0.4747 \t val_acc=0.8630 \t time=84.97s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.0009999982366283705\n",
      "Epoch 2/40 \t loss=0.7025 \t val_loss=0.3121 \t val_acc=0.9233 \t time=85.57s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.0009932375340332778\n",
      "Epoch 3/40 \t loss=0.6101 \t val_loss=0.3010 \t val_acc=0.9260 \t time=85.63s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.0009735681451479374\n",
      "Epoch 4/40 \t loss=0.5411 \t val_loss=0.2633 \t val_acc=0.9342 \t time=86.45s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.0009415265996268716\n",
      "Epoch 5/40 \t loss=0.5656 \t val_loss=0.2532 \t val_acc=0.9397 \t time=85.64s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.0008979869073058199\n",
      "Epoch 6/40 \t loss=0.5391 \t val_loss=0.2429 \t val_acc=0.9425 \t time=85.70s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.0008441367174917935\n",
      "Epoch 7/40 \t loss=0.5197 \t val_loss=0.2237 \t val_acc=0.9479 \t time=85.64s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.0007814449229859509\n",
      "Epoch 8/40 \t loss=0.5174 \t val_loss=0.2652 \t val_acc=0.9288 \t time=85.72s\n",
      "=================================\n",
      "lr: 0.0007116215925171003\n",
      "Epoch 9/40 \t loss=0.5149 \t val_loss=0.2158 \t val_acc=0.9479 \t time=85.54s\n",
      "=================================\n",
      "lr: 0.000636571324524594\n",
      "Epoch 10/40 \t loss=0.4918 \t val_loss=0.2067 \t val_acc=0.9562 \t time=85.67s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.0005583412946778201\n",
      "Epoch 11/40 \t loss=0.4928 \t val_loss=0.2009 \t val_acc=0.9534 \t time=85.51s\n",
      "=================================\n",
      "lr: 0.0004790654142605311\n",
      "Epoch 12/40 \t loss=0.4910 \t val_loss=0.2247 \t val_acc=0.9370 \t time=85.54s\n",
      "=================================\n",
      "lr: 0.00040090612263371365\n",
      "Epoch 13/40 \t loss=0.4578 \t val_loss=0.2145 \t val_acc=0.9507 \t time=85.78s\n",
      "=================================\n",
      "lr: 0.00032599540152688085\n",
      "Epoch 14/40 \t loss=0.4523 \t val_loss=0.2000 \t val_acc=0.9534 \t time=85.77s\n",
      "=================================\n",
      "lr: 0.00025637662013415084\n",
      "Epoch 15/40 \t loss=0.4635 \t val_loss=0.1875 \t val_acc=0.9479 \t time=85.49s\n",
      "=================================\n",
      "lr: 0.00019394879732929929\n",
      "Epoch 16/40 \t loss=0.4323 \t val_loss=0.1885 \t val_acc=0.9507 \t time=85.41s\n",
      "=================================\n",
      "lr: 0.00014041480138125427\n",
      "Epoch 17/40 \t loss=0.4491 \t val_loss=0.1889 \t val_acc=0.9534 \t time=85.60s\n",
      "=================================\n",
      "lr: 9.723490014676583e-05\n",
      "Epoch 18/40 \t loss=0.4251 \t val_loss=0.1772 \t val_acc=0.9616 \t time=85.57s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 6.558692876990959e-05\n",
      "Epoch 19/40 \t loss=0.4193 \t val_loss=0.1810 \t val_acc=0.9671 \t time=85.48s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 4.6334161409741984e-05\n",
      "Epoch 20/40 \t loss=0.4206 \t val_loss=0.1801 \t val_acc=0.9616 \t time=85.50s\n",
      "=================================\n",
      "lr: 4.2622950819672135e-05\n",
      "Epoch 21/40 \t loss=0.4216 \t val_loss=0.2000 \t val_acc=0.9534 \t time=85.50s\n",
      "=================================\n",
      "lr: 0.00019999970610472842\n",
      "Epoch 22/40 \t loss=0.4325 \t val_loss=0.1917 \t val_acc=0.9534 \t time=85.69s\n",
      "=================================\n",
      "lr: 0.00019887292233887962\n",
      "Epoch 23/40 \t loss=0.4397 \t val_loss=0.2183 \t val_acc=0.9562 \t time=85.51s\n",
      "=================================\n",
      "lr: 0.00019559469085798957\n",
      "Epoch 24/40 \t loss=0.4215 \t val_loss=0.1797 \t val_acc=0.9644 \t time=85.59s\n",
      "=================================\n",
      "lr: 0.00019025443327114528\n",
      "Epoch 25/40 \t loss=0.4156 \t val_loss=0.1869 \t val_acc=0.9562 \t time=85.65s\n",
      "=================================\n",
      "lr: 0.00018299781788430332\n",
      "Epoch 26/40 \t loss=0.4052 \t val_loss=0.1920 \t val_acc=0.9534 \t time=85.63s\n",
      "=================================\n",
      "lr: 0.00017402278624863225\n",
      "Epoch 27/40 \t loss=0.4166 \t val_loss=0.1843 \t val_acc=0.9589 \t time=85.57s\n",
      "=================================\n",
      "lr: 0.0001635741538309918\n",
      "Epoch 28/40 \t loss=0.4072 \t val_loss=0.1914 \t val_acc=0.9671 \t time=85.61s\n",
      "=================================\n",
      "lr: 0.00015193693208618339\n",
      "Epoch 29/40 \t loss=0.4109 \t val_loss=0.1902 \t val_acc=0.9562 \t time=85.58s\n",
      "=================================\n",
      "lr: 0.00013942855408743233\n",
      "Epoch 30/40 \t loss=0.4119 \t val_loss=0.1906 \t val_acc=0.9644 \t time=85.45s\n",
      "=================================\n",
      "lr: 0.00012639021577963669\n",
      "Epoch 31/40 \t loss=0.4081 \t val_loss=0.2003 \t val_acc=0.9534 \t time=85.52s\n",
      "=================================\n",
      "lr: 0.00011317756904342184\n",
      "Epoch 32/40 \t loss=0.4006 \t val_loss=0.1825 \t val_acc=0.9616 \t time=85.48s\n",
      "=================================\n",
      "lr: 0.00010015102043895229\n",
      "Epoch 33/40 \t loss=0.3908 \t val_loss=0.1862 \t val_acc=0.9644 \t time=85.48s\n",
      "=================================\n",
      "lr: 8.766590025448016e-05\n",
      "Epoch 34/40 \t loss=0.3858 \t val_loss=0.1738 \t val_acc=0.9644 \t time=85.56s\n",
      "=================================\n",
      "lr: 7.606277002235849e-05\n",
      "Epoch 35/40 \t loss=0.3791 \t val_loss=0.1781 \t val_acc=0.9616 \t time=85.47s\n",
      "=================================\n",
      "lr: 6.565813288821656e-05\n",
      "Epoch 36/40 \t loss=0.3921 \t val_loss=0.1738 \t val_acc=0.9644 \t time=85.36s\n",
      "=================================\n",
      "lr: 5.673580023020905e-05\n",
      "Epoch 37/40 \t loss=0.3881 \t val_loss=0.1884 \t val_acc=0.9644 \t time=85.62s\n",
      "=================================\n",
      "lr: 4.9539150024460975e-05\n",
      "Epoch 38/40 \t loss=0.3821 \t val_loss=0.1749 \t val_acc=0.9671 \t time=85.36s\n",
      "=================================\n",
      "lr: 4.4264488128318265e-05\n",
      "Epoch 39/40 \t loss=0.3755 \t val_loss=0.1786 \t val_acc=0.9671 \t time=85.42s\n",
      "=================================\n",
      "lr: 4.105569356829033e-05\n",
      "Epoch 40/40 \t loss=0.3820 \t val_loss=0.1936 \t val_acc=0.9671 \t time=85.33s\n",
      "=================================\n",
      "best loss: 0.17380848719227698 best accuracy: 0.9671232876712329\n",
      "\n",
      " ********** Fold 1 **********\n",
      "\n",
      "lr: 5.573770491803279e-05\n",
      "Epoch 1/40 \t loss=0.7860 \t val_loss=14.8215 \t val_acc=0.3681 \t time=87.00s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.0009999982366283705\n",
      "Epoch 2/40 \t loss=0.6865 \t val_loss=0.3027 \t val_acc=0.9313 \t time=86.85s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.0009932375340332778\n",
      "Epoch 3/40 \t loss=0.5787 \t val_loss=0.3429 \t val_acc=0.9121 \t time=86.68s\n",
      "=================================\n",
      "lr: 0.0009735681451479374\n",
      "Epoch 4/40 \t loss=0.5898 \t val_loss=0.3066 \t val_acc=0.9121 \t time=86.80s\n",
      "=================================\n",
      "lr: 0.0009415265996268716\n",
      "Epoch 5/40 \t loss=0.5596 \t val_loss=0.2709 \t val_acc=0.9341 \t time=86.86s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.0008979869073058199\n",
      "Epoch 6/40 \t loss=0.5522 \t val_loss=0.2913 \t val_acc=0.9286 \t time=86.79s\n",
      "=================================\n",
      "lr: 0.0008441367174917935\n",
      "Epoch 7/40 \t loss=0.5519 \t val_loss=0.2262 \t val_acc=0.9313 \t time=86.59s\n",
      "=================================\n",
      "lr: 0.0007814449229859509\n",
      "Epoch 8/40 \t loss=0.5103 \t val_loss=0.2460 \t val_acc=0.9451 \t time=86.97s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.0007116215925171003\n",
      "Epoch 9/40 \t loss=0.5034 \t val_loss=0.2148 \t val_acc=0.9533 \t time=86.73s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.000636571324524594\n",
      "Epoch 10/40 \t loss=0.4879 \t val_loss=0.2533 \t val_acc=0.9478 \t time=86.85s\n",
      "=================================\n",
      "lr: 0.0005583412946778201\n",
      "Epoch 11/40 \t loss=0.4955 \t val_loss=0.2146 \t val_acc=0.9505 \t time=86.91s\n",
      "=================================\n",
      "lr: 0.0004790654142605311\n",
      "Epoch 12/40 \t loss=0.4781 \t val_loss=0.2086 \t val_acc=0.9560 \t time=86.92s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.00040090612263371365\n",
      "Epoch 13/40 \t loss=0.4499 \t val_loss=0.2295 \t val_acc=0.9505 \t time=86.84s\n",
      "=================================\n",
      "lr: 0.00032599540152688085\n",
      "Epoch 14/40 \t loss=0.4616 \t val_loss=0.2081 \t val_acc=0.9505 \t time=86.85s\n",
      "=================================\n",
      "lr: 0.00025637662013415084\n",
      "Epoch 15/40 \t loss=0.4381 \t val_loss=0.2074 \t val_acc=0.9505 \t time=86.76s\n",
      "=================================\n",
      "lr: 0.00019394879732929929\n",
      "Epoch 16/40 \t loss=0.4275 \t val_loss=0.1888 \t val_acc=0.9588 \t time=86.95s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.00014041480138125427\n",
      "Epoch 17/40 \t loss=0.4228 \t val_loss=0.1948 \t val_acc=0.9560 \t time=87.07s\n",
      "=================================\n",
      "lr: 9.723490014676583e-05\n",
      "Epoch 18/40 \t loss=0.4153 \t val_loss=0.1763 \t val_acc=0.9615 \t time=87.02s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 6.558692876990959e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/40 \t loss=0.4058 \t val_loss=0.1700 \t val_acc=0.9698 \t time=86.78s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 4.6334161409741984e-05\n",
      "Epoch 20/40 \t loss=0.4074 \t val_loss=0.1818 \t val_acc=0.9588 \t time=86.77s\n",
      "=================================\n",
      "lr: 4.2622950819672135e-05\n",
      "Epoch 21/40 \t loss=0.4010 \t val_loss=0.1847 \t val_acc=0.9615 \t time=86.97s\n",
      "=================================\n",
      "lr: 0.00019999970610472842\n",
      "Epoch 22/40 \t loss=0.4124 \t val_loss=0.2005 \t val_acc=0.9560 \t time=86.79s\n",
      "=================================\n",
      "lr: 0.00019887292233887962\n",
      "Epoch 23/40 \t loss=0.4241 \t val_loss=0.1985 \t val_acc=0.9588 \t time=86.86s\n",
      "=================================\n",
      "lr: 0.00019559469085798957\n",
      "Epoch 24/40 \t loss=0.4176 \t val_loss=0.2160 \t val_acc=0.9423 \t time=86.93s\n",
      "=================================\n",
      "lr: 0.00019025443327114528\n",
      "Epoch 25/40 \t loss=0.4163 \t val_loss=0.1713 \t val_acc=0.9670 \t time=86.99s\n",
      "=================================\n",
      "lr: 0.00018299781788430332\n",
      "Epoch 26/40 \t loss=0.4109 \t val_loss=0.2215 \t val_acc=0.9313 \t time=86.67s\n",
      "=================================\n",
      "lr: 0.00017402278624863225\n",
      "Epoch 27/40 \t loss=0.4008 \t val_loss=0.1796 \t val_acc=0.9588 \t time=86.80s\n",
      "=================================\n",
      "lr: 0.0001635741538309918\n",
      "Epoch 28/40 \t loss=0.4005 \t val_loss=0.1679 \t val_acc=0.9670 \t time=86.86s\n",
      "=================================\n",
      "lr: 0.00015193693208618339\n",
      "Epoch 29/40 \t loss=0.3949 \t val_loss=0.1738 \t val_acc=0.9615 \t time=86.74s\n",
      "=================================\n",
      "lr: 0.00013942855408743233\n",
      "Epoch 30/40 \t loss=0.4081 \t val_loss=0.2081 \t val_acc=0.9478 \t time=86.71s\n",
      "=================================\n",
      "lr: 0.00012639021577963669\n",
      "Epoch 31/40 \t loss=0.4090 \t val_loss=0.2102 \t val_acc=0.9423 \t time=86.88s\n",
      "=================================\n",
      "lr: 0.00011317756904342184\n",
      "Epoch 32/40 \t loss=0.3851 \t val_loss=0.1942 \t val_acc=0.9560 \t time=86.85s\n",
      "=================================\n",
      "lr: 0.00010015102043895229\n",
      "Epoch 33/40 \t loss=0.3832 \t val_loss=0.1864 \t val_acc=0.9560 \t time=86.94s\n",
      "=================================\n",
      "lr: 8.766590025448016e-05\n",
      "Epoch 34/40 \t loss=0.3794 \t val_loss=0.2184 \t val_acc=0.9396 \t time=86.81s\n",
      "=================================\n",
      "lr: 7.606277002235849e-05\n",
      "Epoch 35/40 \t loss=0.3769 \t val_loss=0.1833 \t val_acc=0.9560 \t time=86.92s\n",
      "=================================\n",
      "lr: 6.565813288821656e-05\n",
      "Epoch 36/40 \t loss=0.3775 \t val_loss=0.1728 \t val_acc=0.9615 \t time=86.91s\n",
      "=================================\n",
      "lr: 5.673580023020905e-05\n",
      "Epoch 37/40 \t loss=0.3785 \t val_loss=0.1907 \t val_acc=0.9533 \t time=86.86s\n",
      "=================================\n",
      "lr: 4.9539150024460975e-05\n",
      "Epoch 38/40 \t loss=0.3787 \t val_loss=0.1729 \t val_acc=0.9615 \t time=86.96s\n",
      "=================================\n",
      "lr: 4.4264488128318265e-05\n",
      "Epoch 39/40 \t loss=0.3723 \t val_loss=0.1745 \t val_acc=0.9615 \t time=86.94s\n",
      "=================================\n",
      "lr: 4.105569356829033e-05\n",
      "Epoch 40/40 \t loss=0.3698 \t val_loss=0.1717 \t val_acc=0.9588 \t time=86.84s\n",
      "=================================\n",
      "best loss: 0.16787460614596644 best accuracy: 0.9697802197802198\n",
      "\n",
      " ********** Fold 2 **********\n",
      "\n",
      "lr: 5.573770491803279e-05\n",
      "Epoch 1/40 \t loss=0.8093 \t val_loss=0.4471 \t val_acc=0.8736 \t time=88.00s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.0009999982366283705\n",
      "Epoch 2/40 \t loss=0.6638 \t val_loss=0.3890 \t val_acc=0.8736 \t time=88.05s\n",
      "=================================\n",
      "lr: 0.0009932375340332778\n",
      "Epoch 3/40 \t loss=0.6156 \t val_loss=0.3278 \t val_acc=0.9176 \t time=88.17s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.0009735681451479374\n",
      "Epoch 4/40 \t loss=0.5707 \t val_loss=0.3148 \t val_acc=0.9203 \t time=88.05s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.0009415265996268716\n",
      "Epoch 5/40 \t loss=0.5394 \t val_loss=0.3163 \t val_acc=0.9176 \t time=88.10s\n",
      "=================================\n",
      "lr: 0.0008979869073058199\n",
      "Epoch 6/40 \t loss=0.5353 \t val_loss=0.2834 \t val_acc=0.9231 \t time=88.18s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.0008441367174917935\n",
      "Epoch 7/40 \t loss=0.5050 \t val_loss=0.2743 \t val_acc=0.9286 \t time=88.31s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.0007814449229859509\n",
      "Epoch 8/40 \t loss=0.5277 \t val_loss=0.3028 \t val_acc=0.9203 \t time=88.20s\n",
      "=================================\n",
      "lr: 0.0007116215925171003\n",
      "Epoch 9/40 \t loss=0.4843 \t val_loss=0.2602 \t val_acc=0.9231 \t time=88.15s\n",
      "=================================\n",
      "lr: 0.000636571324524594\n",
      "Epoch 10/40 \t loss=0.4802 \t val_loss=0.2478 \t val_acc=0.9396 \t time=88.22s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.0005583412946778201\n",
      "Epoch 11/40 \t loss=0.4719 \t val_loss=0.2435 \t val_acc=0.9423 \t time=88.25s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.0004790654142605311\n",
      "Epoch 12/40 \t loss=0.4511 \t val_loss=0.2282 \t val_acc=0.9341 \t time=88.29s\n",
      "=================================\n",
      "lr: 0.00040090612263371365\n",
      "Epoch 13/40 \t loss=0.4508 \t val_loss=0.2231 \t val_acc=0.9396 \t time=88.15s\n",
      "=================================\n",
      "lr: 0.00032599540152688085\n",
      "Epoch 14/40 \t loss=0.4354 \t val_loss=0.2231 \t val_acc=0.9423 \t time=88.22s\n",
      "=================================\n",
      "lr: 0.00025637662013415084\n",
      "Epoch 15/40 \t loss=0.4273 \t val_loss=0.2157 \t val_acc=0.9423 \t time=88.11s\n",
      "=================================\n",
      "lr: 0.00019394879732929929\n",
      "Epoch 16/40 \t loss=0.4239 \t val_loss=0.2032 \t val_acc=0.9396 \t time=88.16s\n",
      "=================================\n",
      "lr: 0.00014041480138125427\n",
      "Epoch 17/40 \t loss=0.4072 \t val_loss=0.2054 \t val_acc=0.9423 \t time=88.13s\n",
      "=================================\n",
      "lr: 9.723490014676583e-05\n",
      "Epoch 18/40 \t loss=0.4126 \t val_loss=0.1981 \t val_acc=0.9451 \t time=88.07s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 6.558692876990959e-05\n",
      "Epoch 19/40 \t loss=0.4126 \t val_loss=0.1994 \t val_acc=0.9478 \t time=88.00s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 4.6334161409741984e-05\n",
      "Epoch 20/40 \t loss=0.4039 \t val_loss=0.2044 \t val_acc=0.9368 \t time=88.05s\n",
      "=================================\n",
      "lr: 4.2622950819672135e-05\n",
      "Epoch 21/40 \t loss=0.4158 \t val_loss=0.2269 \t val_acc=0.9396 \t time=88.16s\n",
      "=================================\n",
      "lr: 0.00019999970610472842\n",
      "Epoch 22/40 \t loss=0.4052 \t val_loss=0.2187 \t val_acc=0.9368 \t time=88.06s\n",
      "=================================\n",
      "lr: 0.00019887292233887962\n",
      "Epoch 23/40 \t loss=0.4101 \t val_loss=0.2418 \t val_acc=0.9341 \t time=88.02s\n",
      "=================================\n",
      "lr: 0.00019559469085798957\n",
      "Epoch 24/40 \t loss=0.4006 \t val_loss=0.2047 \t val_acc=0.9396 \t time=87.99s\n",
      "=================================\n",
      "lr: 0.00019025443327114528\n",
      "Epoch 25/40 \t loss=0.4033 \t val_loss=0.2288 \t val_acc=0.9286 \t time=88.04s\n",
      "=================================\n",
      "lr: 0.00018299781788430332\n",
      "Epoch 26/40 \t loss=0.4053 \t val_loss=0.2256 \t val_acc=0.9341 \t time=88.03s\n",
      "=================================\n",
      "lr: 0.00017402278624863225\n",
      "Epoch 27/40 \t loss=0.4076 \t val_loss=0.2482 \t val_acc=0.9396 \t time=87.92s\n",
      "=================================\n",
      "lr: 0.0001635741538309918\n",
      "Epoch 28/40 \t loss=0.4055 \t val_loss=0.2144 \t val_acc=0.9423 \t time=88.06s\n",
      "=================================\n",
      "lr: 0.00015193693208618339\n",
      "Epoch 29/40 \t loss=0.3963 \t val_loss=0.2130 \t val_acc=0.9341 \t time=88.27s\n",
      "=================================\n",
      "lr: 0.00013942855408743233\n",
      "Epoch 30/40 \t loss=0.4012 \t val_loss=0.2063 \t val_acc=0.9341 \t time=88.24s\n",
      "=================================\n",
      "lr: 0.00012639021577963669\n",
      "Epoch 31/40 \t loss=0.3949 \t val_loss=0.1944 \t val_acc=0.9478 \t time=88.14s\n",
      "=================================\n",
      "lr: 0.00011317756904342184\n",
      "Epoch 32/40 \t loss=0.3930 \t val_loss=0.2084 \t val_acc=0.9451 \t time=88.12s\n",
      "=================================\n",
      "lr: 0.00010015102043895229\n",
      "Epoch 33/40 \t loss=0.3809 \t val_loss=0.2161 \t val_acc=0.9478 \t time=88.11s\n",
      "=================================\n",
      "lr: 8.766590025448016e-05\n",
      "Epoch 34/40 \t loss=0.3858 \t val_loss=0.2299 \t val_acc=0.9313 \t time=87.99s\n",
      "=================================\n",
      "lr: 7.606277002235849e-05\n",
      "Epoch 35/40 \t loss=0.3836 \t val_loss=0.2136 \t val_acc=0.9368 \t time=88.11s\n",
      "=================================\n",
      "lr: 6.565813288821656e-05\n",
      "Epoch 36/40 \t loss=0.3746 \t val_loss=0.2055 \t val_acc=0.9451 \t time=88.00s\n",
      "=================================\n",
      "lr: 5.673580023020905e-05\n",
      "Epoch 37/40 \t loss=0.3751 \t val_loss=0.2063 \t val_acc=0.9423 \t time=88.10s\n",
      "=================================\n",
      "lr: 4.9539150024460975e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/40 \t loss=0.3732 \t val_loss=0.2233 \t val_acc=0.9423 \t time=87.94s\n",
      "=================================\n",
      "lr: 4.4264488128318265e-05\n",
      "Epoch 39/40 \t loss=0.3769 \t val_loss=0.2084 \t val_acc=0.9368 \t time=88.10s\n",
      "=================================\n",
      "lr: 4.105569356829033e-05\n",
      "Epoch 40/40 \t loss=0.3752 \t val_loss=0.2151 \t val_acc=0.9396 \t time=87.90s\n",
      "=================================\n",
      "best loss: 0.19439363095068166 best accuracy: 0.9478021978021978\n",
      "\n",
      " ********** Fold 3 **********\n",
      "\n",
      "lr: 5.573770491803279e-05\n",
      "Epoch 1/40 \t loss=0.8272 \t val_loss=0.6108 \t val_acc=0.8104 \t time=89.37s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.0009999982366283705\n",
      "Epoch 2/40 \t loss=0.6755 \t val_loss=0.3153 \t val_acc=0.9313 \t time=89.39s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.0009932375340332778\n",
      "Epoch 3/40 \t loss=0.6244 \t val_loss=0.3884 \t val_acc=0.8764 \t time=89.33s\n",
      "=================================\n",
      "lr: 0.0009735681451479374\n",
      "Epoch 4/40 \t loss=0.5858 \t val_loss=0.2616 \t val_acc=0.9258 \t time=89.22s\n",
      "=================================\n",
      "lr: 0.0009415265996268716\n",
      "Epoch 5/40 \t loss=0.5437 \t val_loss=0.2468 \t val_acc=0.9203 \t time=89.31s\n",
      "=================================\n",
      "lr: 0.0008979869073058199\n",
      "Epoch 6/40 \t loss=0.5619 \t val_loss=0.2387 \t val_acc=0.9286 \t time=89.31s\n",
      "=================================\n",
      "lr: 0.0008441367174917935\n",
      "Epoch 7/40 \t loss=0.5513 \t val_loss=0.2541 \t val_acc=0.9368 \t time=89.29s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.0007814449229859509\n",
      "Epoch 8/40 \t loss=0.5052 \t val_loss=0.1895 \t val_acc=0.9560 \t time=89.15s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.0007116215925171003\n",
      "Epoch 9/40 \t loss=0.5212 \t val_loss=0.3335 \t val_acc=0.9038 \t time=89.24s\n",
      "=================================\n",
      "lr: 0.000636571324524594\n",
      "Epoch 10/40 \t loss=0.4947 \t val_loss=0.2462 \t val_acc=0.9341 \t time=89.41s\n",
      "=================================\n",
      "lr: 0.0005583412946778201\n",
      "Epoch 11/40 \t loss=0.4883 \t val_loss=0.2249 \t val_acc=0.9313 \t time=89.49s\n",
      "=================================\n",
      "lr: 0.0004790654142605311\n",
      "Epoch 12/40 \t loss=0.4764 \t val_loss=0.1910 \t val_acc=0.9533 \t time=89.25s\n",
      "=================================\n",
      "lr: 0.00040090612263371365\n",
      "Epoch 13/40 \t loss=0.4672 \t val_loss=0.1886 \t val_acc=0.9560 \t time=89.37s\n",
      "=================================\n",
      "lr: 0.00032599540152688085\n",
      "Epoch 14/40 \t loss=0.4401 \t val_loss=0.1767 \t val_acc=0.9615 \t time=89.33s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.00025637662013415084\n",
      "Epoch 15/40 \t loss=0.4534 \t val_loss=0.2215 \t val_acc=0.9478 \t time=89.43s\n",
      "=================================\n",
      "lr: 0.00019394879732929929\n",
      "Epoch 16/40 \t loss=0.4402 \t val_loss=0.1606 \t val_acc=0.9670 \t time=89.24s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.00014041480138125427\n",
      "Epoch 17/40 \t loss=0.4308 \t val_loss=0.1686 \t val_acc=0.9615 \t time=89.42s\n",
      "=================================\n",
      "lr: 9.723490014676583e-05\n",
      "Epoch 18/40 \t loss=0.4171 \t val_loss=0.1555 \t val_acc=0.9643 \t time=89.26s\n",
      "=================================\n",
      "lr: 6.558692876990959e-05\n",
      "Epoch 19/40 \t loss=0.4144 \t val_loss=0.1575 \t val_acc=0.9670 \t time=89.15s\n",
      "=================================\n",
      "lr: 4.6334161409741984e-05\n",
      "Epoch 20/40 \t loss=0.4155 \t val_loss=0.1589 \t val_acc=0.9698 \t time=89.42s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 4.2622950819672135e-05\n",
      "Epoch 21/40 \t loss=0.4181 \t val_loss=0.1703 \t val_acc=0.9670 \t time=89.10s\n",
      "=================================\n",
      "lr: 0.00019999970610472842\n",
      "Epoch 22/40 \t loss=0.4162 \t val_loss=0.1580 \t val_acc=0.9780 \t time=89.15s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.00019887292233887962\n",
      "Epoch 23/40 \t loss=0.4199 \t val_loss=0.1554 \t val_acc=0.9588 \t time=89.31s\n",
      "=================================\n",
      "lr: 0.00019559469085798957\n",
      "Epoch 24/40 \t loss=0.4340 \t val_loss=0.1532 \t val_acc=0.9698 \t time=89.38s\n",
      "=================================\n",
      "lr: 0.00019025443327114528\n",
      "Epoch 25/40 \t loss=0.4096 \t val_loss=0.1522 \t val_acc=0.9643 \t time=89.22s\n",
      "=================================\n",
      "lr: 0.00018299781788430332\n",
      "Epoch 26/40 \t loss=0.4279 \t val_loss=0.1611 \t val_acc=0.9615 \t time=89.26s\n",
      "=================================\n",
      "lr: 0.00017402278624863225\n",
      "Epoch 27/40 \t loss=0.4144 \t val_loss=0.1406 \t val_acc=0.9835 \t time=89.21s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.0001635741538309918\n",
      "Epoch 28/40 \t loss=0.4046 \t val_loss=0.1418 \t val_acc=0.9698 \t time=89.13s\n",
      "=================================\n",
      "lr: 0.00015193693208618339\n",
      "Epoch 29/40 \t loss=0.4145 \t val_loss=0.1730 \t val_acc=0.9643 \t time=89.21s\n",
      "=================================\n",
      "lr: 0.00013942855408743233\n",
      "Epoch 30/40 \t loss=0.4029 \t val_loss=0.1600 \t val_acc=0.9670 \t time=89.19s\n",
      "=================================\n",
      "lr: 0.00012639021577963669\n",
      "Epoch 31/40 \t loss=0.3981 \t val_loss=0.1380 \t val_acc=0.9725 \t time=89.19s\n",
      "=================================\n",
      "lr: 0.00011317756904342184\n",
      "Epoch 32/40 \t loss=0.3916 \t val_loss=0.1440 \t val_acc=0.9725 \t time=89.31s\n",
      "=================================\n",
      "lr: 0.00010015102043895229\n",
      "Epoch 33/40 \t loss=0.3852 \t val_loss=0.1653 \t val_acc=0.9643 \t time=89.22s\n",
      "=================================\n",
      "lr: 8.766590025448016e-05\n",
      "Epoch 34/40 \t loss=0.3841 \t val_loss=0.1464 \t val_acc=0.9615 \t time=89.31s\n",
      "=================================\n",
      "lr: 7.606277002235849e-05\n",
      "Epoch 35/40 \t loss=0.3848 \t val_loss=0.1420 \t val_acc=0.9643 \t time=89.34s\n",
      "=================================\n",
      "lr: 6.565813288821656e-05\n",
      "Epoch 36/40 \t loss=0.3852 \t val_loss=0.1461 \t val_acc=0.9670 \t time=89.39s\n",
      "=================================\n",
      "lr: 5.673580023020905e-05\n",
      "Epoch 37/40 \t loss=0.3879 \t val_loss=0.1589 \t val_acc=0.9643 \t time=89.26s\n",
      "=================================\n",
      "lr: 4.9539150024460975e-05\n",
      "Epoch 38/40 \t loss=0.3905 \t val_loss=0.1522 \t val_acc=0.9670 \t time=89.27s\n",
      "=================================\n",
      "lr: 4.4264488128318265e-05\n",
      "Epoch 39/40 \t loss=0.3735 \t val_loss=0.1464 \t val_acc=0.9698 \t time=89.11s\n",
      "=================================\n",
      "lr: 4.105569356829033e-05\n",
      "Epoch 40/40 \t loss=0.3721 \t val_loss=0.1403 \t val_acc=0.9615 \t time=89.18s\n",
      "=================================\n",
      "best loss: 0.13800982626215105 best accuracy: 0.9835164835164835\n",
      "\n",
      " ********** Fold 4 **********\n",
      "\n",
      "lr: 5.573770491803279e-05\n",
      "Epoch 1/40 \t loss=0.7973 \t val_loss=1.1725 \t val_acc=0.7802 \t time=90.50s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.0009999982366283705\n",
      "Epoch 2/40 \t loss=0.7001 \t val_loss=0.4564 \t val_acc=0.8736 \t time=90.52s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.0009932375340332778\n",
      "Epoch 3/40 \t loss=0.6097 \t val_loss=0.2909 \t val_acc=0.9368 \t time=91.10s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.0009735681451479374\n",
      "Epoch 4/40 \t loss=0.6156 \t val_loss=0.4084 \t val_acc=0.8874 \t time=90.51s\n",
      "=================================\n",
      "lr: 0.0009415265996268716\n",
      "Epoch 5/40 \t loss=0.5897 \t val_loss=0.2907 \t val_acc=0.9176 \t time=90.41s\n",
      "=================================\n",
      "lr: 0.0008979869073058199\n",
      "Epoch 6/40 \t loss=0.5186 \t val_loss=0.2664 \t val_acc=0.9313 \t time=90.61s\n",
      "=================================\n",
      "lr: 0.0008441367174917935\n",
      "Epoch 7/40 \t loss=0.5183 \t val_loss=0.2174 \t val_acc=0.9423 \t time=90.48s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.0007814449229859509\n",
      "Epoch 8/40 \t loss=0.4999 \t val_loss=0.2642 \t val_acc=0.9341 \t time=90.42s\n",
      "=================================\n",
      "lr: 0.0007116215925171003\n",
      "Epoch 9/40 \t loss=0.5265 \t val_loss=0.2576 \t val_acc=0.9341 \t time=90.42s\n",
      "=================================\n",
      "lr: 0.000636571324524594\n",
      "Epoch 10/40 \t loss=0.4908 \t val_loss=0.2358 \t val_acc=0.9396 \t time=90.57s\n",
      "=================================\n",
      "lr: 0.0005583412946778201\n",
      "Epoch 11/40 \t loss=0.4674 \t val_loss=0.1993 \t val_acc=0.9478 \t time=90.56s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.0004790654142605311\n",
      "Epoch 12/40 \t loss=0.4777 \t val_loss=0.2079 \t val_acc=0.9588 \t time=90.53s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.00040090612263371365\n",
      "Epoch 13/40 \t loss=0.4587 \t val_loss=0.1833 \t val_acc=0.9615 \t time=90.73s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.00032599540152688085\n",
      "Epoch 14/40 \t loss=0.4551 \t val_loss=0.1784 \t val_acc=0.9560 \t time=90.57s\n",
      "=================================\n",
      "lr: 0.00025637662013415084\n",
      "Epoch 15/40 \t loss=0.4419 \t val_loss=0.1926 \t val_acc=0.9560 \t time=90.75s\n",
      "=================================\n",
      "lr: 0.00019394879732929929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/40 \t loss=0.4354 \t val_loss=0.1832 \t val_acc=0.9670 \t time=90.65s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 0.00014041480138125427\n",
      "Epoch 17/40 \t loss=0.4184 \t val_loss=0.1659 \t val_acc=0.9753 \t time=90.54s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 9.723490014676583e-05\n",
      "Epoch 18/40 \t loss=0.4120 \t val_loss=0.1653 \t val_acc=0.9808 \t time=90.52s\n",
      "model saved!\n",
      "=================================\n",
      "lr: 6.558692876990959e-05\n",
      "Epoch 19/40 \t loss=0.4208 \t val_loss=0.1596 \t val_acc=0.9725 \t time=90.44s\n",
      "=================================\n",
      "lr: 4.6334161409741984e-05\n",
      "Epoch 20/40 \t loss=0.4051 \t val_loss=0.1617 \t val_acc=0.9698 \t time=90.40s\n",
      "=================================\n",
      "lr: 4.2622950819672135e-05\n",
      "Epoch 21/40 \t loss=0.4119 \t val_loss=0.2056 \t val_acc=0.9615 \t time=90.47s\n",
      "=================================\n",
      "lr: 0.00019999970610472842\n",
      "Epoch 22/40 \t loss=0.4292 \t val_loss=0.1706 \t val_acc=0.9643 \t time=90.49s\n",
      "=================================\n",
      "lr: 0.00019887292233887962\n",
      "Epoch 23/40 \t loss=0.4382 \t val_loss=0.1942 \t val_acc=0.9643 \t time=90.41s\n",
      "=================================\n",
      "lr: 0.00019559469085798957\n",
      "Epoch 24/40 \t loss=0.4245 \t val_loss=0.1645 \t val_acc=0.9670 \t time=90.71s\n",
      "=================================\n",
      "lr: 0.00019025443327114528\n",
      "Epoch 25/40 \t loss=0.4329 \t val_loss=0.1780 \t val_acc=0.9643 \t time=90.67s\n",
      "=================================\n",
      "lr: 0.00018299781788430332\n",
      "Epoch 26/40 \t loss=0.4187 \t val_loss=0.1778 \t val_acc=0.9670 \t time=90.48s\n",
      "=================================\n",
      "lr: 0.00017402278624863225\n",
      "Epoch 27/40 \t loss=0.4061 \t val_loss=0.1737 \t val_acc=0.9643 \t time=90.45s\n",
      "=================================\n",
      "lr: 0.0001635741538309918\n",
      "Epoch 28/40 \t loss=0.3999 \t val_loss=0.1629 \t val_acc=0.9698 \t time=90.53s\n",
      "=================================\n",
      "lr: 0.00015193693208618339\n",
      "Epoch 29/40 \t loss=0.4010 \t val_loss=0.1738 \t val_acc=0.9643 \t time=90.31s\n",
      "=================================\n",
      "lr: 0.00013942855408743233\n",
      "Epoch 30/40 \t loss=0.3986 \t val_loss=0.1657 \t val_acc=0.9698 \t time=90.48s\n",
      "=================================\n",
      "lr: 0.00012639021577963669\n",
      "Epoch 31/40 \t loss=0.3969 \t val_loss=0.1511 \t val_acc=0.9670 \t time=90.46s\n",
      "=================================\n",
      "lr: 0.00011317756904342184\n",
      "Epoch 32/40 \t loss=0.3914 \t val_loss=0.1488 \t val_acc=0.9670 \t time=90.29s\n",
      "=================================\n",
      "lr: 0.00010015102043895229\n",
      "Epoch 33/40 \t loss=0.3879 \t val_loss=0.1512 \t val_acc=0.9643 \t time=90.40s\n",
      "=================================\n",
      "lr: 8.766590025448016e-05\n",
      "Epoch 34/40 \t loss=0.3842 \t val_loss=0.1495 \t val_acc=0.9725 \t time=90.36s\n",
      "=================================\n",
      "lr: 7.606277002235849e-05\n",
      "Epoch 35/40 \t loss=0.3903 \t val_loss=0.1641 \t val_acc=0.9753 \t time=90.27s\n",
      "=================================\n",
      "lr: 6.565813288821656e-05\n",
      "Epoch 36/40 \t loss=0.3871 \t val_loss=0.1552 \t val_acc=0.9670 \t time=90.17s\n",
      "=================================\n",
      "lr: 5.673580023020905e-05\n",
      "Epoch 37/40 \t loss=0.3801 \t val_loss=0.1538 \t val_acc=0.9698 \t time=90.34s\n",
      "=================================\n",
      "lr: 4.9539150024460975e-05\n",
      "Epoch 38/40 \t loss=0.3796 \t val_loss=0.1545 \t val_acc=0.9615 \t time=90.19s\n",
      "=================================\n",
      "lr: 4.4264488128318265e-05\n",
      "Epoch 39/40 \t loss=0.3749 \t val_loss=0.1545 \t val_acc=0.9588 \t time=90.21s\n",
      "=================================\n",
      "lr: 4.105569356829033e-05\n",
      "Epoch 40/40 \t loss=0.3781 \t val_loss=0.1502 \t val_acc=0.9670 \t time=90.48s\n",
      "=================================\n",
      "best loss: 0.14882543202369444 best accuracy: 0.9807692307692307\n",
      "CV loss:0.164582 \t CV accuracy:0.969798\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log = open('./exp/exp' + str(EXP) +'/log.txt', 'w')\n",
    "log.write('IMG_SIZE%d\\n'%IMG_SIZE)\n",
    "log.write('SEED%d\\n'%SEED)\n",
    "cv_losses = []\n",
    "cv_metrics = []\n",
    "\n",
    "for fold in range(FOLD):\n",
    "    print('\\n ********** Fold %d **********\\n'%fold)\n",
    "    ###################### Dataset #######################\n",
    "    trainset     = PlantDataset(train_df.iloc[tr_idx[fold]].reset_index(), transform =train_transform_advprop)\n",
    "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "\n",
    "    valset       = PlantDataset(train_df.iloc[val_idx[fold]].reset_index(), transform   =test_transform)\n",
    "    val_loader   = torch.utils.data.DataLoader(valset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "    ####################### Model ########################\n",
    "#     model_conv = EfficientNet.from_pretrained(\"efficientnet-b5\", advprop=True)\n",
    "    model_conv = ptcv_get_model(\"seresnext101_32x4d\", pretrained=True)\n",
    "#     model_conv._dropout = nn.Dropout(p=0.5)\n",
    "#     model_conv._avg_pooling = AdaptiveConcatPool2d(1)\n",
    "    model_conv.features.final_pool = nn.AdaptiveAvgPool2d(1)\n",
    "#     model_conv._fc = nn.Sequential(nn.Linear(2048*2,256), Mish(), nn.Dropout(p=0.5), nn.Linear(256,4))\n",
    "    model_conv.output = nn.Sequential(nn.Linear(2048,256), Mish(), nn.Dropout(p=0.5), nn.Linear(256,4))\n",
    "    model_conv.cuda()\n",
    "\n",
    "    ###################### Optim ########################\n",
    "    optimizer = torch.optim.AdamW(model_conv.parameters(), lr=LR/25., weight_decay=1e-4)\n",
    "\n",
    "    criterion = LSR()\n",
    "    criterion_test = nn.CrossEntropyLoss()\n",
    "\n",
    "    T = len(train_loader)//ACCUMULATE * 20 # cycle\n",
    "    scheduler = CosineAnnealingWarmUpRestarts(optimizer, T_0=T, T_mult=1, eta_max=LR, T_up=T//20, gamma=0.2)\n",
    "    scheduler.step()\n",
    "\n",
    "    model_conv, optimizer = amp.initialize(model_conv, optimizer, opt_level=\"O1\",verbosity=0)\n",
    "    \n",
    "    val_loss, val_acc = train(fold)\n",
    "    \n",
    "    cv_losses.append(val_loss)\n",
    "    cv_metrics.append(val_acc)\n",
    "    log.write('[Flod%d] val loss:%.5f \\t val acc:%.5f; \\n'%(fold, val_loss, val_acc))\n",
    "\n",
    "cv_loss = sum(cv_losses)/FOLD   \n",
    "cv_acc = sum(cv_metrics)/FOLD   \n",
    "print('CV loss:%.6f \\t CV accuracy:%.6f'%(cv_loss, cv_acc))\n",
    "log.write('CV loss:%.6f \\t CV accuracy:%.6f'%(cv_loss, cv_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./exp/exp9/pipeline.ipynb'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.copyfile('./pipeline-ls.ipynb', './exp/exp' + str(EXP) + '/pipeline.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
